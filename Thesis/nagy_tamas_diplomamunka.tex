\documentclass[a4paper,12pt]{report}


\usepackage[latin2]{inputenc} % vagy latin2 helyett utf8
\usepackage[T1]{fontenc}      % karakterkódolás
\usepackage[magyar]{babel}    % magyar beállítások
\frenchspacing                % helyközök
%\usepackage{times}           % betûtípus
\usepackage{lmodern}          %   vagy inkább ez

\usepackage[margin=2.5cm,left=3.5cm,includeheadfoot]{geometry}
                              % margók
\usepackage{graphicx}         % képekhez
\usepackage{grffile}
\usepackage{setspace}         % sorköz
\onehalfspacing               % másfeles

\usepackage{hyperref}		  % table of contents hyperlink
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{chngcntr}
\usepackage{siunitx}
\usepackage{float}

%\usepackage[nottoc,numbib]{tocbibind}

%\counterwithout{figure}{chapter}

\graphicspath {{figures/}}

\addto\captionsmagyar{ \renewcommand{\listfigurename}{Ábrajegyzék} }
\addto\captionsmagyar{ \renewcommand{\abstractname}{Absztrakt} }

\begin{document}

% ------------------------------------------------------------------------------
% Címlap

\input{cimlap.tex}

% ------------------------------------------------------------------------------
% Témabejelentõ

%\vspace*{\fill}

%\vfill
%\thispagestyle{empty}
%\newpage
%\setcounter{page}{1}


% ------------------------------------------------------------------------------

\begin{abstract}
	A távérzékelt felvételek felhasználási területeinek folyamatos bõvülésével 
	egyre nagyobb az igény olyan megoldások kutatására, melyek a mûholdak által 
	szolgáltatott hatalmas mennyiségû adathalmazt olcsón és hatékonyan tudják kezelni és 
	feldolgozni. A napjainkban tömegesen hozzáférhetõ számítógépek kapacitása
	azonban már nem elegendõ több, a felvételek feldolgozásában részt vevõ mûvelet számára.
	Ezzel párhuzamosan a számítástudomány fókusza az elosztott rendszerek felé irányult. %TODO Recompose
	Az elosztott rendszerek területén az utóbbi idõben két jelentõs paradigma nyert teret.
	A MapReduce paradigmára építõ rendszerek között találhatunk kifejezetten a térinformatikára
	és a távérzékelt felvételek feldolgozására felkészített keretrendszereket, az ágens (aktor)
	modellre épülõ platformok közül azonban még nem jelentek meg téradatokat támogató kiterjesztések.
	
	Jelen dolgozat célja az ágens alapú Orleans keretrendszer gyakorlati alkalmazhatóságának 
	vizsgálata távérzékelt felvételek feldolgozása esetén. A felvételek kiértékelése 
	során használt mûveletek mûvelettípusai elosztott feldolgozás esetén eltérõ megközelítést 
	igényelnek. A dolgozat bemutatja ezen mûvelettípusok ágens alapú feldolgozásának 
	akadályaira adott megoldásait, az elért eredményeket pedig összeveti az egyik 
	legnépszerûbb MapReduce alapú keretrendszer, a Hadoop platform teljesítményével.
	
	A mért eredmények azt mutatják, hogy az ágens alapú megközelítés nem optimális
	távérzékelt felvételek feldolgozásának területén. Az Orleans keretrendszer csupán
	néhány mûvelet esetén tudott jobb eredményeket elérni, mint a Hadoop rendszer,
	azonban a felvételek tematikus osztályozási folyamatának egyik állomásán sem 
	volt képes olyan eredmény elérésére, amely felvehetné a versenyt a Hadoop-,
	vagy a lokális feldolgozás teljesítményével.
	
\end{abstract}

% ------------------------------------------------------------------------------
% Tartalomjegyzék

\tableofcontents

% ------------------------------------------------------------------------------

\chapter{Bevezetés}
Napjaink egyik legnagyobb kihívása a rendelkezésre álló természeti erõforrások hatékony kihasználása.
A Föld népességének ugrásszerû növekedésével a világ élelem-, és nyersanyagszükséglete az emberiség
történelmében most a legmagasabb. A rendelkezésre álló megújuló természeti erõforrások azonban végesek és sebezhetõek.
A növénytermesztés területén például a fejlõdõ növényzetet több veszélyforrás 
is fenyegetheti (aszály, belvíz, gyomnövények, állati kártevõk). %TODO Gombák, betegségek
Ezek a veszélyforrások emberi beavatkozás nélkül jelentõs hozambeli csökkenést, rosszabb esetben pedig a teljes növényzet
pusztulását okozhatják. A növényzet fejlõdésének pillanatnyi állapotáról rendelkezésre álló információ
birtokában azonban ezek a káros folyamatok felismerhetõek, és bizonyos óvintézkedések alkalmazása esetén
visszafordíthatóak.

Hasonlóképpen a fát, mint nyersanyagot szolgáltató erdõk is jelentõs veszélyforrásoknak vannak kitéve 
(állati kártevõk, erdei fafajok betegségei). Ha ezek a veszélyforrások idõben felismerésre kerülnek,
még orvosolhatók a faállomány jelentõs méretû károsodása nélkül.

Látható, hogy természeti erõforrásaink folyamatos, manuális megfigyelése hatalmas 
ráfordított emberi energiával és pénzbeli költségekkel jár. 
Ez olyan monitorozási megoldások kutatását indikálta, 
amellyel az egységnyi területre jutó megfigyelés költsége csökkenthetõ.

A 60-as években az ûrtechnika fejlõdése, és a látható tartományon kívüli elektromágneses sugárzások felvételezésére
alkalmas szenzorok fejlesztése elvezetett az elsõ, távérzékelt felvételeket szolgáltató mûholdak üzembe
állításához. Ezzel egy új tudományág, a távérzékelés tudománya indult útjára.

A mûholdak egyszerre hatalmas területrõl szolgáltatnak információt, ezeket az információkat pedig
az élet számos területén hatékonyan felhasználhatjuk, a fent említett növény-, és erdõvédelem
mellett például természeti katasztrófák (pl.: \textit{árvíz}) monitorozására.
A szolgáltatott felvételek kiértékelése kezdetben manuálisan történt, majd a számítástechnika
fejlõdésével megjelent az igény a részben, vagy egészben automatizált feldolgozásra.

A távérzékelt felvételek automatikus feldolgozásának nagy részében felhasználhatóak voltak a digitális
képelemzés területén elért eredmények, így a fókusz új mûveletek kutatása és fejlesztése helyett 
a feldolgozás teljesítményének növelésére irányult. A mûholdak által szolgáltatott felvételek részlegességüktõl
függõen hatalmas méretûek lehetnek, így a hozzáférés és a kiértékelés gyorsasága 
a távérzékelés legtöbb területén (pl.: katasztrófa-monitoring) kiemelt fontosságú. 
A távérzékelt felvételek feldolgozása kezdetben egyetlen számítógép felhasználásával történt,
a hálózatok megjelenésével azonban megjelent az igény olyan elosztott rendszerek 
fejlesztésére, amelyek lehetõvé tették egyszerre több számítógép összekapcsolását 
és erõforrásaik együttes kihasználását, ezáltal jelentõsen növelve a feldolgozás teljesítményét.
Ezek az elosztott rendszerek leggyakrabban két fõ paradigmára épülnek. A napjainkban nagy
népszerûségnek örvendõ \textit{MapReduce} alapú rendszerek mellett az utóbbi idõben az
\textit{ágens (aktor) modell}re épülõ rendszerek is teret nyertek. 

Jelen dolgozat célja az \textit{Orleans} ágens alapú keretrendszer távérzékelt felvételek
feldolgozásának területén való alkalmazhatóságának vizsgálata. Ha
a keretrendszer megfelelõ teljesítményt tud nyújtani a kiértékelésre használt
mûveletek futtatása során, akkor hatékonyan beilleszthetõ a feldolgozás folyamatába, ezáltal
az adatok kiértékelési ideje jelentõsen csökkenthetõ.

A keretrendszer hatékonyságát a távérzékelt felvételek feldolgozásában részt vevõ
mûveletek hatékonyságával tesztelhetjük.
Ennek megfelelõen számos mûvelet került vizsgálatra a feldolgozás
mindegyik fázisából (\textit{elõfeldolgozás, képjavító mûveletek, tematikus osztályozás}), 
melyek az Orleans keretrendszerben egyedi megközelítést igényeltek. 
A rendszer alkalmazhatóságának vizsgálata érdekében a mûveletek futtatása során
mért teljesítmény összevetésre kerül az egy számítógépen történõ feldolgozás teljesítményével,
valamint a MapReduce rendszerek zászlóshajójának számító \textit{Hadoop} platformon mért eredményekkel.
\newline

A dolgozat felépítése a következõ: a \ref{ch:remoteSensingAnalysis}. fejezetben
átfogó bemutatásra kerülnek a távérzékelés fizikai és technikai alapjai, valamint
a távérzékelt felvételek kiértékelésének folyamata, lépései, illetve ezek tulajdonságai.
Ezt a \ref{ch:distributedSystems}. fejezetben az elosztott alkalmazások fejlesztésének
alapjai, a felhasználható paradigmák, illetve ezek \linebreak implementációinak bemutatása követi.
A \ref{ch:aegis}. fejezet ismerteti az Orleans keretrendszer térinformatikai kiegészítéséhez
felhasznált keretrendszert, az AEGIS keretrendszert. Az Orleans platform teljesítményének
vizsgálatához egy prototípus alkalmazás megvalósítása volt szükséges, ennek felépítését
és komponenseit a \ref{ch:application}. fejezet tartalmazza. A prototípus alkalmazás
bemutatása után az egyes vizsgált mûveletek ismertetése következik, ezt a \ref{ch:algorithms}.
fejezet tartalmazza. A \ref{ch:results}. fejezet ismerteti a keretrendszer által elért eredményeket,
valamint összehasonlítja a Hadoop platform-, és az egy számítógépen történõ feldolgozás
teljesítményével. Végül a \ref{ch:summary}. fejezet összegzi és értékeli a dolgozat 
által elért eredményeket, emellett pedig összefoglalja a megszerzett tapasztalatokat.

% ------------------------------------------------------------------------------

\chapter{Távérzékelt felvételek elemzése} \label{ch:remoteSensingAnalysis}
A fejezet célja betekintést nyújtani távérzékelt felvételkiértékelés folyamatába.
Elsõként a távérzékelés fogalma, fizikai és technikai alapjai, valamint alkalmazási lehetõségei kerülnek ismertetésre.
Ezután a távérzékelt felvételek kiértékelésének célja, feldolgozási folyamata,
és a folyamat során elvégzett mûveletek bemutatása következik.

\section{A Távérzékelés}
Távérzékelés alatt olyan adatgyûjtési és feldolgozási eljárásokat értünk, melynek során
tárgyakról vagy területekrõl közvetve, azok érintése nélkül gyûjtünk és rögzítünk adatokat.

Manapság a távérzékelést leggyakrabban földfelszíni-, illetve légköri adatok begyûjtésére értjük, valamilyen légi, vagy ûrbéli szenzor segítségével. 
Ezek a szenzorok a földfelszínrõl érkezõ (kibocsátott, vagy visszavert) elektromágneses 
energiát érzékelik, ez által alkotnak képet egy bizonyos területrõl.\cite{richards}

\subsection{A távérzékelés fizikai és technikai alapjai} \label{subs:remoteSensingBasics}
A távérzékelõ rendszereknek alapvetõen három fõ összetevõje van: A \textit{sugárforrás}, a megfigyelés tárgyát képezõ \textit{földfelszín} és az \textit{érzékelõ}.

A sugárforrás alapján beszélhetünk \textit{passzív}-, illetve \textit{aktív} távérzékelõ szenzorokról.
A passzív szenzorok valamilyen természetes energia sugárzását érzékelik, ez lehet a Föld által kibocsátott, vagy
visszavert energia. A Passzív szenzorok által leggyakrabban használt sugárforrás a Napból érkezõ energia.
Az aktív szenzorok abban különböznek passzív társaiktól, hogy õk maguk sugározzák a földfelszínre az érzékelni kívánt energiát.

A távérzékelt felvételek \textit{spektrális felbontás}a meghatározza, hogy az elektromágneses spektrumon belül mely
hullámsávokat milyen részletességgel vételezi a szenzor. Az úgynevezett \textit{pankromatikus} szenzorok egy spektrális
sávot felvételeznek, mely lefedi a teljes látható tartományt, valamint belenyúlhat a közeli infravörös tartományba.
A \textit{multispektrális} szenzorok több különbözõ elektromágneses hullámsávban érzékelnek. A leggyakrabban használt
multispektrális szenzorok sávszáma 3 és 7 között van, és a reflektív tartomány mellett 
a termális infravörös sávot is felvételezik.

Az érzékelõ berendezés az egyes hullámsávokban beérkezõ elektromágneses intenzitást 
alakítja digitális értékekké (\textit{Digital Number - DN}). Ezen kvantálás finomságát az
érzékelõk \textit{radiometriai felbontás}a határozza meg. 
Minél több energiaszintet képes megkülönböztetni az szenzor, annál magasabb
radiometriai felbontással rendelkezik. A legelterjedtebb nagyfelbontású multispektrális szenzoroknál 
a \textit{7-8 bites felbontás} jellemzõ, mely \textit{128}, illetve \textit{256} különbözõ intenzitásszintnek felel meg.

Egy többsávos digitális felvételezés eredménye egy olyan mátrixként értelmezhetõ, melynek minden eleme egy elemi
felszíndarabnak felel meg - a mátrix elemeinek pozíciója kapcsolatban van a felvételezett felszíndarab földrajzi
helyzetével. Az egyes mátrixértékek maguk is vektorok, melyek elemei a megadott felszíndarabon belül az egyes
spektrális sávokban mért intenzitásértékeket tartalmazzák. Egy \textit{N} sorból és \textit{M} oszlopból álló
többsávos digitális felvétel az alábbi formulában írható le:

\begin{center}
$
V = 
\begin{pmatrix}
\vec{v}_{11} & \cdots & \vec{v}_{1\textit{M}} \\
\vdots  & \ddots & \vdots  \\
\vec{v}_{\textit{N}1} & \cdots & \vec{v}_{\textit{NM}} 
\end{pmatrix}
$,
\end{center}

ahol B számú spektrális sávot feltételezve $\vec{v}_{\textit{ij}} = (v_{\textit{ij}1}, \hdots, v_{\textit{ijB}})$
az egyes elemekhez tartozó intenzitásértékek vektora. A vektor egyes elemei mindegyik spektrális sávban (kvantált formában)
megadják az adott intenzitásértéket, tehát: $v_{\textit{ijb}} \in [\textit{1}\hdots\textit{H}]$, ahol \textit{H} a
radiometriai felbontás alapján ábrázolható maximális értéket jelöli.\cite{remoteSensingLecture}

\subsection{Távérzékelt felvételek alkalmazási területei}
Az élet számos területén felhasználhatóak a távérzékeléssel nyert információk, például:
\begin{itemize}
	\item \textbf{Katasztrófavédelem} 
	\newline 
	Hurrikánok, földrengések, erózió, árvíz megfigyelése. A távérzékelt adatokat felhasználhatjuk a
	természeti katasztrófa hatásainak kiértékelésére, az információ alapján megelõzõ lépéseket tehetünk a jelenlegi helyzet kezelésére, valamint a jövõbeni katasztrófákra is felkészülhetünk.
	
	\item \textbf{Természeti erõforrások monitorozása }
	\newline
	Földhasználat, vadvilági területek monitorozása. A távérzékelt adatok felhasználásával minimalizálhatjuk a
	városi növekedés káros hatásait a környezetre, valamint dönthetünk, hogyan védhetjük természeti erõforrásainkat.

	\item \textbf{Mezõgazdasági termés,- illetve hozambecslés }
	\newline
	A távérzékelt adatok segítségével becslést adhatunk a monitorozott termõterület hozamára, illetve megelõzhetjük
	a termést veszélyeztetõ növények és állatok kártételét.
\end{itemize}

A felhasználási területek közül fõként a katasztrófavédelemnél kiemelten fontos, hogy \textit{milyen gyakran},
és az érzékelés pillanatától számítva \textit{mennyi késéssel} juthatunk hozzá a kiértékelt adatokhoz.
Árvíz esetén például órák alatt változhat a vízszint, amelyrõl ha idõben
értesülünk, megtehetjük a megfelelõ óvintézkedéseket, késlekedés esetén azonban jelentõs károk 
keletkezhetnek. 

Az eredmény elõállításának sebességét két tényezõ befolyásolja. 
Egyrészt az \textit{adatok hozzáférési ideje}, mely azt adja meg, mennyi idõ telik el
a felvételkészítéstõl addig, amíg a felvételek eljutnak a felhasználóhoz. 
Kritikus lehet emellett az \textit{adatok kiértékelésének sebessége} is, tehát hogy mennyi
idõ alatt állítható elõ a felvételezett képbõl a szükséges információ.

\section{Távérzékelt felvételek feldolgozása}
A távérzékelés általánosságban a \textit{felvételezés}tõl a \textit{tematikus információ-kivonás}ig tart. 
A felvételezés során a szenzorra beérkezõ intenzitásértékek nem tükrözik hûen a földfelszín sugárzását, 
így elsõ lépésként a felvételeket egy \textit{elõfeldolgozó fázis}ban korrigálni kell.
Ezután a felvételek \textit{tematikus kiértékelés}e következik, mely történhet 
manuálisan vagy automatizáltan, esetleg a kettõ keverékeként. A tematikus kiértékelés 
módja befolyással lehet arra, mely elõfeldolgozó mûveletek végrehajtása szükséges.

\subsection{Elõfeldolgozás} \label{ssn:preProcessing}
A mûholdak által szolgáltatott nyers digitális értékek számos hibaforrással lehetnek terheltek, melyek korrigáció nélküli
felhasználása hibás kiértékelést eredményez.
Ide tartoznak például a \textit{légköri zavaró hatások} (páratartalom, hõmérséklet-különbségek), a felvevõ rendszer és
hordozóeszközének mozgási szabálytalanságaiból adódó \textit{torzítás}ok, valamint a szomszédos területekrõl való \textit{átsugárzás}.
A hibaforrások kiküszöbölése mellett a hatékony feldolgozás érdekében érdemes minden felvételt egységes geometriai rendszerbe transzformálva
kezelni, ezt a mûveletet \textit{geometriai korrekció}nak nevezünk.

\textit{Intenzitás-korrekció} alatt azokat a mûveleteket értjük, melyekkel a felvétel képpontjaihoz és az egyes spektrális 
sávokhoz tartozó sávonkénti intenzitást módosítjuk. A ténylegesen végrehajtandó intenzitás-mûveleteket nagyban befolyásolja
a felhasználás célja, mivel az emberi szem és agy más szempontok alapján képes különbséget tenni a felvételen látható
felszínborítások között, mint a kvantitatív számítógépes mûveletek.

Az intenzitás-korrekció csoportjába tartozik például a \textit{radiometriai korrekció}, valamint a különbözõ \textit{látványjavító mûveletek}.
A radiometriai korrekció arra szolgál, hogy a szenzor által mért digitális számértékekbõl megkapjuk
a földfelszín fizikai paramétereit. 
A rendelkezésre álló korrekciós adatok és a feldolgozás igénye meghatározza,
hogy milyen szintû korrekcióra van szükség:

\begin{itemize}
	\item A \textit{spektrális radiancia} a szenzorra érkezõ elektromágneses sugárzás intenzitása, 
		mely a digitális értékekkel	legtöbbször lineáris kapcsolatban áll. 
		A leíró függvény paraméterei a szenzorok korától és beállításaitól függõen 
		változhatnak, így a felvételek elengedhetetlen paraméterei.
		
	\item A \textit{ToA-Reflektancia} (\textit{Top of Atmosphere Reflectance} - \textit{légkör tetején mérhetõ reflektancia}), 
		a felszín visszaverésének olyan közelítése, mely nem veszi figyelembe a sugárzás és a légkör közötti kölcsönhatást.
		A ToA-Reflektancia a radianciából számítható, figyelembe véve a \textit{Nap}, a \textit{felvételezett terület} 
		és a \textit{szenzor} geometriai viszonyát egymáshoz képest, 
		valamint az \textit{irradianciát} (a beesõ napsugárzás intenzitása)
		
	\item A \textit{felszíni reflektancia} a ToA-reflektanciából számítható a légköri korrekció végrehajtásával,
		tehát az olyan kölcsönhatások eliminálásával, amelyek a sugárzásra a légkörben történõ áthaladása során hatnak
		(például \textit{ózon}, \textit{szén-dioxid} vagy a \textit{vízpára}).
	
\end{itemize}

Az egyes \textit{látványjavító mûveletek} célja a felvétel vizuális megjelenítési tulajdonságainak megváltoztatása az emberi szemmel történõ
értelmezés könnyítése érdekében. Látványjavító mûvelet például az \textit{invertálás}, illetve 
a különbözõ \textit{szûrések}. 
A látványjavító mûveletek egy részében (pl.: szûrések) ténylegesen megváltoznak a pixelértékek, 
ebben az esetben 
a javítás után már nem végezhetõ el a numerikus kiértékelés, mivel elveszítjük a földfelszín konkrét
fizikai paramétereit.\cite{remoteSensingLecture}

\subsection{Tematikus osztályozás}
A felvételkiértékelés célja a felszínborítás, földfelszíni objektumok fizikai jellemzõinek megállapítása. A felvételkiértékelés két alapvetõ módszere a 
\textit{vizuális interpretáció} és a \textit{kvantitatív, numerikus kiértékelés}. 

A vizuális interpretáció során a tematikus döntéseket a felvételen \textit{látható} információ alapján hozza meg a
kiértékelõ személy - ez olyan esetekben hatékony eljárás, amikor \textit{geometriai összefüggések}, 
\textit{struktúrák} felismerésére van szükség, melyet a számítógép nem képes azonosítani.

Numerikus kiértékelés esetén a tematikus döntések meghozatala a számítógépen, 
elõre megadott feltételek alapján történik. A számítógépes feldolgozás elõnye, hogy nagy mennyiségû
adat feldolgozására is alkalmas, illetve az egyes textúrák közötti tónuskülönbségek mérésében és elkülönítésében
is jobban teljesít, mint az emberi szem és agy rendszere. Mivel mindkét módszer 
jelentõs elõnyökkel és hátrányokkal rendelkezik egymáshoz képest, 
gyakran együttesen kerülnek alkalmazásra. 

A \textit{tematikus osztályozás} egy kvantitatív kiértékelési mód, melynek célja egy olyan tematikus térkép
elkészítése, mely véges számú célosztállyal írja le a vizsgált területet. A tematikus térkép minden pixeléhez a
célosztály egy értéke tartozik. A tematikus osztályozási módszerek lehetnek \textit{pontonkénti mûvelet}ek, valamint \textit{szegmensenkénti mûvelet}ek.

A pontonkénti mûveletek minden egyes képpontra külön meghatározzák a tartalmazó célosztályt, így figyelmen 
kívül hagyják a homogén területek szomszédos képpontjainak azonosságát. 
Pontonkénti mûveletek például az egyes \textit{küszöbölõ eljárás}ok, melyek során az spektrális intenzitás intervallumot
egy vagy több különbözõ részre vágjuk, ezek a részek fogják alkotni a célosztályokat. A pixelek spektrális intenzitása
meghatározza hogy melyik részintervallumba, és ez által melyik célosztályba kerülnek. A vágási pont(ok) meghatározása
történhet manuálisan (pl.: \textit{konstans küszöbölés}), valamint automatikusan a kép valamilyen tulajdonsága 
(legtöbbször a \textit{hisztogram}) alapján.

A \textit{szegmensenkénti mûvelet}ek, homogén területek sorozatán képesek elvégezni az osztályozást. 
Ezen homogén területek feltárásának és összekapcsolásának módja a \textit{szegmentálás}.
A szegmentálás eredményeként egy olyan tematikus térképet kapunk, mely minden képpontra megadja a pontot 
tartalmazó szegmens sorszámát. Az eredményszegmensek a legtöbb esetben nem feleltethetõek meg egyértelmûen az
elérni kívánt célosztályoknak, számuk jellemzõen nagyságrendekkel nagyobb. 
Az összetartozó szegmensek összevonása és ezáltal célosztályokká redukálása a \textit{klaszterezõ} eljárások feladata.

\begin{figure}[h!]
	\centering
	\captionsetup{width=1\textwidth, justification=centering}
	\includegraphics[width=110mm]{figures/coordinateSystem.jpg}
	\caption{Felszíndarabok sugárzása  $x_1=0.5\si{\micro\metre}$ 
		és $x_2=0.9\si{\micro\metre}$ hullámhosszon \label{fig:intensitySpaces}}
\end{figure}

A klaszterezõ mûveletek a szegmensek \textit{intenzitástér}ben való elhelyezkedése alapján 
határolják be az egyes elemeket a megfelelõ osztályokba. Az intenzitástérben a kép egy pixelének sávonkénti
intenzitásértékei adják a pont koordinátáit. A \ref{fig:intensitySpaces}. ábrán látható, hogy az egyes intenzitásértékek
jellemzõen nem pontokba tömörülnek, hanem rendelkeznek bizonyos mértékû szórással. A klaszterezés során
ezen térben keressük az összetartozó elemeket, és ez alapján alakítjuk ki a végsõ osztályhalmazokat.\cite{remoteSensingLecture}

\subsection{Feldolgozó mûveletek munkaterülete}
A feldolgozó mûveletek munkaterülete azt határozza meg, hogy a mûvelet egy lépésének végrehajtásához 
az input kép mekkora részére van szükség. Ez alapján négy csoportot különböztetünk meg:

\begin{itemize}
	\item \textit{Lokális mûvelet:} A forrás egy megadott képpontjából a cél egy képpontját állítja elõ,
	lényegében egy pontból pontba történõ transzformáció. Ebbe a csoportba tartoznak az egyszerûbb képi
	transzformációk (például az \textit{invertálás}), valamint az egyes \textit{küszöbölõ} algoritmusok.
	\item \textit{Fokális mûvelet:} Egy megadott képpont kiszámításához annak valamilyen sugarú környezetében lévõ
	értékek felhasználásával dolgozik. Ide tartoznak például a különbözõ \textit{szûrõ} mûveletek.
\end{itemize}

\begin{figure}[h!]
	\minipage{0.5\textwidth}
	\includegraphics[width=\linewidth]{figures/localOperation.png}
	{\caption{Lokális mûvelet\cite{mapAlgebra}}}\label{fig:localOperation}
	\endminipage\hfill
	\minipage{0.5\textwidth}
	\includegraphics[width=\linewidth]{figures/focalOperation.png}
	\caption{Fokális mûvelet\cite{mapAlgebra}}\label{fig:focalOperation}
	\endminipage\hfill
\end{figure}

\begin{itemize}
	\item \textit{Regionális (zonális) mûvelet:}
	A regionális mûveletek hasonlóak a fokális mûveletekhez, leszámítva hogy míg a fokális mûveletnél 
	a képpont kiszámításához szükséges környezet egy elõre definiált
	méretû terület, addig a zonális mûveletnél a szükséges környezet az õt tartalmazó régió (zóna), 
	mely a feldolgozás során dinamikusan változhat. Regionális mûvelet például a legtöbb \textit{szegmentáló}
	algoritmus
	
	\item \textit{Globális mûvelet:} Az eredménykép minden képpontjának elõállításához rendelkeznie kell a teljes
	forráskép ismeretével. Ide tartoznak például azok a \textit{küszöbölõ eljárások}, melyek
	a küszöbértéket a teljes képbõl számított valamilyen statisztika (pl.: hisztogram) alapján határozzák meg. 
	A legtöbb \textit{klaszterezõ algoritmus} is ebbe a kategóriába tartozik, mivel a klaszterek
	kialakítása	során a képpont fizikai elhelyezkedését már nem vesszük figyelembe, csupán a 
	spektrális intenzitástérben lévõ pozícióját.
\end{itemize}

\begin{figure}[h!]
	\minipage{0.5\textwidth}
	\includegraphics[width=\linewidth]{figures/zonalOperation.png}
	{\caption{Regionális mûvelet\cite{mapAlgebra}}}\label{fig:zonalOperation}
	\endminipage\hfill
	\minipage{0.5\textwidth}
	\includegraphics[width=\linewidth]{figures/globalOperation.png}
	\caption{Globális mûvelet\cite{mapAlgebra}}\label{fig:globalOperation}
	\endminipage\hfill
\end{figure}
 
\section{Adatkezelés}
Az alkalmazási területeknél már említésre került, hogy a feldolgozási idõ kritikus lehet az adatkiértékelés szempontjából.
Ezt nehezíti az a tény, hogy a kiértékelõ eljárások többsége meglehetõsen komplex, illetve hogy gyakran hatalmas mennyiségû
adathalmazzal kell dolgoznunk.
Ez felveti olyan megoldások kutatásának szükségességét, amellyel a kiértékelés ideje csökkenthetõ.

A legkézenfekvõbb lehetõség a feldolgozó egységek \textit{számítási kapacitás}ának megnövelése. Erõsebb \textit{processzor}, 
több \textit{memória}, I/O mûveletek gyorsabb elvégzésére alkalmas \textit{háttértár}ak
beszerzése esetén a számítási teljesítményünk is növekszik. A megoldás legnagyobb elõnye, hogy a meglévõ algoritmusok a megnövelt 
teljesítményû környezetben is felhasználhatóak, a feldolgozás szoftveres része nem igényel adaptációt. Azonban a
rendszer teljesítménynövelésének ezen módja költséges, és a fejlesztéssel nyert számítási kapacitás aránya egy bizonyos szint után csökken.

A teljesítménynövelés másik lehetséges módja az évek óta kutatott\cite{distributedImageProcessing}, és a számítási
felhõk elterjedésével az utóbbi idõben leginkább teret nyert \textit{elosztott feldolgozás}.

Távérzékelt felvételek elosztott feldolgozása úgy történik, hogy a feldolgozandó kép alkotóelemeit valamilyen tulajdonság alapján 
(pixel értékek, spektrális intenzitásértékek) \textit{feldarabolunk} (\textit{particionálás}), az egyes feldolgozó egységek pedig ezen darabokat dolgozzák fel.
Ekkor - a mûvelet korábban ismertetett munkaterületének megfelelõen - a feldolgozó egységeknek szükségük lehet olyan információkra, melyek
a teljes adat egy részének vagy egészének ismeretében számíthatók csak ki.

Egyszerûbb, fokális esetben ezt megoldhatjuk \textit{átfedések} alkalmazásával - az input adatot úgy particionáljuk,
hogy az eredetileg neki szánt területnél valamennyivel nagyobb területet tartalmazzon. Ekkor az 
átfedések segítségével akár partíció felhasználása nélkül is kiszámítható az eredmény.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=80mm]{figures/imagePartitioning_withOverlap.png}
	\caption{Input kép feldarabolása \textit{átfedés}ek alkalmazásával \label{fig:imagePartitioning}}
\end{figure}

Regionális esetben is felhasználhatóak az átfedett területek, azonban ekkor
nincs információnk a folyamat elindításának pillanatában, mekkora területre 
lesz szükség az egyes képpontok kiszámításához, ez az információ a 
mûvelet futása alatt dinamikusan változhat. Emiatt csak jelentõs méretû átfedés definiálásával
érhetjük el, hogy nagy valószínûséggel minden feldolgozó egység számára elég legyen 
a rendelkezésre álló terület. Egy másik megközelítés lehet, ha a feldolgozó egységek a mûvelet végrehajtása során 
egymással kommunikálva biztosítják a számításokhoz szükséges adatokat. 
Ebben az esetben a rendszer teljesítményét leginkább meghatározó szempont ezen adatok gyors és hatékony rendelkezésre állása.

A legtöbb globális mûvelet is elvégezhetõ particionált módon, itt azonban mindenképp szükséges 
egy központi összefuttató lépés - ennek módszere az alkalmazott mûvelettõl függ.\cite{remoteSensingLecture}

% ------------------------------------------------------------------------------

\chapter{Elosztott alkalmazások fejlesztése} \label{ch:distributedSystems}
A fejezetben bemutatásra kerülnek az elosztott szoftverrendszerek elméleti alapjai, 
ezek néhány megvalósítása, valamint
távérzékelt felvételek feldolgozásában lévõ alkalmazási lehetõségeik, külön részletezve a dolgozat
témáját, a \textit{Microsoft Orleans} platformot.

Az \textit{elosztott rendszerek} olyan szoftverrendszerek, melyek komponensei fizikailag elkülönítve futnak, és futás során
egymással hálózaton keresztül kommunikálnak. A komponensek saját processzorral és memóriával rendelkeznek (Szemben a párhuzamos
rendszerekkel, amelyek a memóriát megosztják egymással).

Az elosztott architektúra több jelentõs elõnnyel is rendelkezik az egy számítási egységgel rendelkezõ rendszerrel szemben:
\textit{skálázhatóság} (a folyamat áteresztõképességének növelésének képessége), nagyobb \textit{hibatûrés}, 
hatékony \textit{terheléselosztás}, olcsó \textit{bõvíthetõség}.
Az elosztott feldolgozás hátránya a \textit{komplexitás}ában nyilvánul meg - 
az egyes komponensek egymással való \textit{hálózati kommunikáció}ját 
biztosítani kell, a kommunikációból adódó késést figyelembe kell venni, illetve kezelni kell a fellépõ \textit{konkurenciá}t.
A hibaelhárítás, valamint a diagnosztizálás is sokkal bonyolultabbá válhat egy elosztott rendszerben.

Ezen tényezõk indokolták olyan \textit{keretrendszerek} és \textit{architekturális koncepciók} kutatását, 
melyek az elosztott alkalmazások fejlesztésének nehézségeire részben vagy egészben megoldást nyújtanak.
A következõ részekben ezen koncepciók és néhány megvalósításuk kerül bemutatásra.

\section{MapReduce}
A \textit{MapReduce} nagy adathalmazok generálására és feldolgozására fejlesztett számítási modell.\cite{mapReduce}
Egy MapReduce alkalmazás alkotóelemei \textit{Map} és \textit{Reduce} funkciók. A \textit{Map} funkció az input
elemeibõl köztes \textit{kulcs/érték párok}at állít elõ, a \textit{Reduce} mûvelet pedig összevonja az összes olyan
köztes elemet, melynek kulcsa megegyezik.
A MapReduce paradigma alapján írt programok automatikusan párhuzamosíthatók, és skálázhatók. 
A futtatókörnyezet végzi az adatok \textit{particionálás}át, vezérli a \textit{végrehajtás}t, kezeli a 
\textit{gépek közötti kommunikáció}t és a fellépõ hibákat.
Ezzel lehetõséget nyújt elosztott környezetek erõforrásainak kihasználására anélkül, hogy a fejlesztõktõl 
komoly szaktudást követelne a párhuzamos és elosztott alkalmazásfejlesztés területén.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=120mm]{figures/mapReduce.jpg}
	\caption{A \textit{MapReduce} folyamat \label{fig:mapReduceProcess}}
\end{figure}

\subsection{Hadoop} \label{subs:aegisHadoop}
A MapReduce modell egy implementációja az \textit{Apache Software Foundation} által fejlesztett 
\textit{Hadoop} keretrendszer. A rendszer komponenseinek tervezésénél a fõ szempont a hibatûrés volt - 
bármilyen hardveres hiba elõfordulása természetes, és a keretrendszernek automatikusan kezelnie kell.

A rendszer három fõ komponensbõl áll: A \textit{Hadoop Elosztott Fájlrendszer}bõl 
(\textit{HDFS - Hadoop Distributed File System}), a \textit{Hadoop MapReduce} adatfeldolgozóból, valamint
a \textit{Hadoop YARN}-ból, mely a rendszer erõforrás-kezelõje.
A feldolgozandó input fájlokat elõször a HDFS-be töltjük fel. Ezeket a fájlokat
a Hadoop automatikusan blokkokra osztja és az egyes blokkokat replikálva szétosztja 
az elosztott rendszert alkotó gépek között.

A feldolgozás során a Hadoop a feldolgozó szoftvert tölti fel minden feldoldogzásban
részt vevõ számítógépre, így az adatok helyben kerülnek feldolgozásra (\textit{adatlokalitás}).

\subsubsection{Térinformatikai alkalmazása}
A Hadoop keretrendszer fejlesztésekor az alkalmazás fõ célterülete szöveges adatok 
feldolgozása volt, terjedésével azonban megjelent az igény az informatika több 
különbözõ területén való alkalmazására. 
Ennek megfelelõen megjelentek a keretrendszer térinformatikai 
kiterjesztései is\cite{spatialHadoop,hadoopGIS}, melyek
támogatják téradatok \textit{tárolás}át, \textit{indexelés}ét, és MapReduce alapú 
\textit{feldolgozás}át.

Az egyes feldolgozó mûveletek közül a lokális, illetve a fokális mûveletek könnyedén alkalmazhatók
egyszerû \textit{Map} függvényekként. Regionális és globális esetben általában szükséges egy olyan
alternatív algoritmus bevezetése, amely az eredeti algoritmus kiegészítése egy (vagy több) 
\textit{Reduce} lépéssel.

\begin{figure}[H]
	\centering
	\includegraphics[width=150mm]{figures/histogram_map_reduce.jpg}
	\caption{Hisztogramkiegyenlítés \textit{MapReduce} alkalmazásával\cite{aegisHadoop}
		\label{fig:histogram_map_reduce}}
\end{figure}

Például a \textit{hisztogram kiegyenlítés} mûvelet egy globális mûvelet, melynek szüksége van az egész képre vonatkozó
hisztogram értékekre. Ekkor Hadoop architektúrán a mûvelet három különbözõ lépésbõl áll. Elõször egy \textit{Map}
függvényben kiszámítjuk az egyes hisztogram értékeket minden fájldarabra. A második, \textit{Reduce} lépés
összefésüli ezeket az értékeket, és elõállítja a teljes hisztogramot. A harmadik lépésben pedig egy újabb \textit{Map}
utasítás alkalmazza a hisztogramkiegyenlítést a kiszámított teljes hisztogramértékek alapján.

Összességében elmondható\cite{aegisHadoop}, hogy a legtöbb esetben a mûveletek könnyedén adaptálhatók Hadoop környezetbe, 
azonban néhány alkalommal komplex módosításokra van szükség, és a portolt algoritmus helyfoglalási igénye sokkal nagyobb
lehet, mint az eredeti mûveleté. Ezen tényezõk indokolták további alternatív feldolgozó mechanizmusok kutatásának szükségét.

\section{Aktor modell}
Az \textit{Aktor modell} egy olyan konkurens matematikai modell, melynek alapegységei az "\textit{aktorok}" \cite{actorOrig}.
Az aktorok egymástól izolált egységek, melyek direkt módon, aszinkron, 
\textit{módosíthatatlan (immutable)} üzeneteken keresztül kommunikálnak egymással.
Minden aktor rendelkezik egy "\textit{postaládával}", ahová az üzenetek érkeznek.
Az aktorok mûködésük során mindig valamilyen üzenetre regagálnak - számítást 
végezhetnek, aktorokat hozhatnak létre, további üzeneteket küldhetnek, valamint 
beállíthatják, hogyan fognak reagálni a következõ üzenetre.
Az üzenetek érkezési sorrendje nem garantált, de követelmény, hogy minden üzenet beérkezzen.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=120mm]{figures/actorModel.png}
	\caption{Az \textit{aktor modell}.\label{fig:actorModel}}
\end{figure}

Az aktorok jellemzõen egy számítási szállal rendelkeznek, és nem osztanak meg memóriát egymás között. 
Ez eliminálja a versenyhelyzetek kezelésének szükségességét aktor szinten. 
A fejlesztõknek nem szükséges \textit{lock}olást, \textit{mutex}eket és más versenyhelyzet-kezelõ megoldásokat
alkalmazniuk, melyek nem tartoznak az alkalmazás logikájához. Az aktorok létrehozása
egyes implementációkban történhet manuálisan, vagy a rendelkezésre álló 
erõforrások alapján dinamikusan, ezáltal hatékony terheléselosztás alkalmazható.

Az aktor modell akkor alkalmazható hatékonyan, ha az aktorok "könnyûsúlyúak", gyorsan példányosíthatók,
és folyamatuk nincs a rendszermag szálaihoz kötve, attól eltérõen ütemezhetõ.

\subsubsection{Aktor implementációk}
A modellt elõször az \textit{Erlang} programozási nyelvben alkalmazták konkurens 
alkalmazások fejlesztésére\cite{actorErlang}, majd népszerûségének 
növekedésével több nyelv és keretrendszer is sikeresen 
adaptálta a modellt, pl.: a \textit{Scala}\cite{actorScala}, 
vagy az \textit{Akka} keretrendszer\cite{actorAkka}.

Ezek az aktor modell implementációk - jóllehet hatékony megoldást adnak az elosztott 
alkalmazásfejlesztésre - több elosztott rendszerrel kapcsolatos probléma kezelését a 
fejlesztõkre bízzák. A fejlesztõknek kezelniük kell az aktorok életciklusát (hiba 
esetén történõ leállás esetén az aktorok újraaktiválását), és a rendszerben
történõ elhelyezését. Ezek a limitációk, és a 
kiküszöbölésükre való törekvés hívta életre a \textit{Microsoft Orleans} keretrendszert.

\section{A Microsoft Orleans platform}
Az \textit{Orleans} egy - a \textit{Microsoft Research} által fejlesztett - keretrendszer, 
mely lehetõséget ad megbízható és skálázható felhõalapú alkalmazások fejlesztésére.

Az Orleans programozási modellje (\textit{Virtual Actor Model - Virtuális Aktor Modell})
az aktor modell egy olyan kiterjesztése, amely az aktorokat virtuális entitásokként 
kezeli. Ez eliminálja a az elosztott erõforráskezelés és a megbízhatóság alkalmazás
szinten történõ kezelésének szükségességét, megszünteti a konkurenciát, ezáltal
nem követel komplex tudást a fejlesztõktõl az elosztott alkalmazásfejlesztés területén.

A keretrendszert a \textit{Microsoft Azure} számítási \textit{felhõben} több jelenleg is futó projekten 
hatékonyan alkalmazták, 2015 januárjában pedig nyílt forráskódú licenccel a nyilvánosság elé tárták.

\subsection{Virtuális aktor modell}
Az Orleans rendszer egy módosított aktor modellt definiál, amelyet elosztott alkalmazások, valamint az
Erlang nyelv modellének implementációja ihletett, és teljes egészében a .NET keretrendszerre épül.
Az Orleans aktorok, vagyis \textit{Grain}-ek (szabad fordításban \textit{szemcse, gabonaszem}) a rendszer legkisebb
számítási alapegységei. Egy aktor enkapszulálja az állapotát és a viselkedését, és nem
oszt meg memóriát más aktorokkal, így két aktor között az egyetlen kommunikációs mód az aszinkron üzenetküldés.

Az aktorok az Orleans rendszerben az eredeti modelltõl eltérõen virtuálisak. 
Egy aktor elméletben mindig létezik, nem hozható létre és nem semmisíthetõ
meg manuálisan. Az aktorok létezése nem függ a példányok számától, és nem függ futtató szerver állapotától.
Mivel az aktorok elméletben mindig léteznek, ezért mindig elérhetõek.
Az Orleans futtatókörnyezet automatikusan kezeli az aktorok példányosítását (\textit{aktiváció}) és megsemmisítését. 
Az alkalmazás futása során minden idõpillanatban egy aktor 0, 1 vagy több aktivációval rendelkezik.
Ha egy üzenet érkezik egy aktornak, és nincs egyetlen aktivációja sem, a rendszer létrehoz egy példányt az egyik elérhetõ 
szerveren (\textit{Orleans Silo}), valamint ha a példány egy bizonyos ideig kihasználatlanul marad, 
a futtatókörnyezet elvégzi a példány deaktiválását és felszabadítását. Ha egy szerver hiba miatt leáll, az 
Orleans egy másik elérhetõ szerveren automatikusan újrapéldányosítja azokat az aktorokat, 
amelyek a hibás szerveren futottak, és a nekik küldött üzeneteket erre az új szerverre irányítja.
Az alkalmazásoknak így nincs szükségük különbözõ \textit{életciklus felügyelet}i logika bevezetésére
(pl.: \textit{felügyeleti fák} az Erlang nyelvben\cite{erlang}).
Az aktorok automatikus példányosítása és életciklus-kezelése azt is eredményezi, 
hogy az aktorok fizikai elhelyezkedésérõl a futó alkalmazásnak nincs tudomása - 
egy bizonyos idõpillanatban egy aktornak akár 0 vagy egynél több aktivációja is lehet
különbözõ szervereken, ezt a keretrendszer tartja nyilván.

Jelenleg az Orleans rendszer kétféle aktivációs módot támogat: az \textit{állapot}tal rendelkezõ aktorok
egyszerre maximum egy aktivációval rendelkezhetnek, míg az \textit{állapotmentes} (\textit{Stateless Worker})
aktoroknak szimultán több egymástól független aktivációja is megengedett a klaszterben.

\subsubsection{Aktorok kommunikációja}
Az egyes aktorok azokon a metódusokon keresztül tudnak kommunikálni egymással, 
melyek az \textit{aktor interfész}ében definiálásra kerültek. 
Az interfészen definiált összes metódus \textit{aszinkron} kell, hogy legyen.

Ahhoz, hogy egy aktor üzenetet küldhessen egy másik aktornak, az aktor
\textit{referenciá}jával kell rendelkeznie.
Ezek a referenciák virtuálisak abban a tekintetben, hogy nem 
szolgálnak semmilyen információval a referált aktor fizikai elhelyezkedésérõl. 
A kommunikáció egy lokális \textit{proxy objektum}on keresztül történik, és az üzenetet
a futtatókörnyezet továbbítja a tényleges aktornak.

Az egyes üzenetek szerializálva kerülnek továbbításra - a .NET keretrendszer által
definiált \texttt{[Serializable]}
attribútummal ellátott objektumok is használhatók, és az Orleans keretrendszer is rendelkezik
beépített szerializálóval, amely képes tömbök, illetve generikus objektumok 
szerializálására is, mindezek mellett pedig megtartja az objektumok identitását 
(ha két pointer ugyanarra az objektumra mutat, akkor deszerializálás után 
is ugyanarra az objektumra fognak mutatni).

\subsubsection{Elosztottság, Fordulók} 
Az aktorok minden aktivációja egyszálú, és \textit{fordulók}nak nevezett részletekben dolgoznak.
Az Orleans rendszer különbözõ aktivációk fordulóit futtathatja párhuzamosan, azonban minden
aktiváció csupán egy fordulót dolgoz fel egyszerre.
Ennek eredményeként aktor szinten nem jelenik meg párhuzamosság a rendszerben.
A forduló alapú modell ugyan megengedi több kérés fordulóinak átfedését 
(pl.: Amíg az egyik forduló egy \textit{I/O mûvelet} befejeztére vár,
egy másik forduló feldolgozása is elkezdõdhet), azonban ezt az Orleans rendszer
alapértelmezetten nem engedélyezi. Ez a viselkedés felüldefiniálható, és a fordulók
átfedhetnek, ha az aktor osztályt megjelöljük a \texttt{[Reentrant]} attribútummal.

\subsection{A keretrendszer implementációja}
Az Orleans rendszer szerverek egy csoportján fut, és három fõ alrendszere van - 
\textit{Üzenetküldés}, \textit{Végrehajtás} valamint \textit{Futtatókörnyezet}.

Az Üzenetküldés alrendszer minden szervert egyszerû TCP kapcsolattal köt össze, 
és több kommunikációs szálon keresztül továbbítja az egyes üzeneteket.

A Környezet alrendszer dönt az aktivációk elhelyezésérõl a klaszterben, a
Végrehajtás pedig a rendelkezésre álló számítási szálak alapján futtatja az
aktorok kódját.

Amikor egy aktor egy másik aktort hív, a Végrehajtás a függvényhívást üzenetté
konvertálja, és átadja az Üzenetküldésnek a cél aktor identitásával együtt.
Az Üzenetküldés lekéri a Futtatókörnyezettõl, hogy melyik szerver hosztolja
az aktort. A Futtatókörnyezet egy \textit{elosztott könyvtár} segítségével tartja nyilván
az aktorok összes aktivációját a rendszerben. A könyvtárban vagy egy létezõ aktivációt
talál, vagy kiválaszt egy szervert, és létrehoz egy új aktivációt. Az Üzenetküldés 
ezután szerializálja az üzenetet, és a nyitott TCP kapcsolaton keresztül továbbítja 
a célszervernek. A célszerver Üzenetküldés alrendszere deszerializálja az üzenetet,
és átadja a Végrehajtásnak, mely ezután ütemezi a hívást. Ha egy aktor éppen egy
másik hívást dolgoz fel, az üzenet sorban áll addig, amíg a feldolgozás be nem fejezõdik.

A környezet felel a lokális erõforrások kezeléséért is. Ha egy aktorra egy bizonyos
(elõre definiált) ideje nem volt szükség, vagy ha a szerver erõforráshiányt észlel,
a környezet automatikusan deaktiválja az aktort, és visszaveszi az erõforrásait.

\subsubsection{Izoláció}
Az Orleans aktorok nem osztanak meg memóriát és izoláltak egymástól.
Az aszinkron üzenetküldés az egyedüli kommunikációs mód köztük, amelyek
metódusok formájában jelennek meg az aktorok interfészén. Ezen felül a metódushívások
paraméterei és visszatérési értékei a hívás során lemásolódnak (még akkor is,
ha a metódushívás két ugyanazon a szerveren lévõ aktor között megy végbe),
ezzel biztosítva az elküldött üzenet módosíthatatlanságát.

\subsubsection{Kooperatív multitasking}
Az Orleans az egyes fordulókat \textit{kooperatív multitasking} formában ütemezi. Ez azt jelenti, hogy
egy alkalmazás forduló az elindítása után megszakítás nélkül végrehajtódik. Az Orleans ütemezõje
az aktorok futtatásához és ütemezéséhez tipikusan annyi számítási szálat használ, 
amennyi processzormaggal rendelkezik az adott rendszer. 

Egy komplex rendszerben az aktor aktivációk száma akár milliós nagyságrendû is lehet. 
\textit{Preemptív multitasking} használata esetén az összes aktiváció saját szálat kapna, ez pedig egy bizonyos
számú aktiváció felett több lenne, mint amit a rendszerek képesek kezelni, ráadásul a kontextusváltás
drága, így ez is rontana a teljesítményen.

\subsubsection{Megbízhatóság}
A rendszer a megbízhatóság összes aspektusát automatikusan kezeli, kivéve az aktorok perzisztens állapotának
menedzselését. A rendszer automatikusan menedzseli a klaszterben lévõ szervereket. Az egyes szerverek
\textit{ping} üzeneteket küldenek egymásnak, és ha egy bizonyos szervertõl több másik szerver sem kap választ,
akkor a szervert leálltnak tekintik.

Ha egy szerver leállt, az összes rajta futó aktiváció elveszik. Ekkor a többi szervernek ezekre az aktivációkra
vonatkozó információkat ki kell törölniük a rendszer elosztott könyvtárából. 
Mivel az aktorok virtuálisak, egy aktor nem áll le ha az õt futtató szerver leáll.
Ehelyett a következõ üzenet, amelyet a leállt szerveren lévõ aktornak küldenek, egy új aktivációt fog létrehozni
egy másik, élõ szerveren. 

Egy aktor állapotának mentési stratégiája nagymértékben függ az aktor feladatától. Ha például
az aktorunk egy eszközt (\textit{mobiltelefon}, \textit{szenzor}) reprezentál, melyet az eszköz az adataival
periodikusan frissít, akkor nem szükséges elmentenünk az aktor állapotát, mivel az új aktiváció a következõ
frissítéssel küldött adatokból képes lesz azt elõállítani.
Ha nem engedhetünk meg állapotvesztést, akkor a mentés minden üzenet feldolgozása után szükséges, 
vagy megengedõbb esetben, megadott idõközönként esedékes a mentés.

Tekintve, hogy egy aktor (és az egész rendszer) teljesítményét nagymértékben befolyásolhatja, és minden aktorra
különbözhet a mentési stratégia, a rendszer nem kezeli az állapotok automatikus mentését, ezt a fejlesztõkre bízza. 

\subsubsection{Aktorok elhelyezése}
Az Orleans rendszer futása során automatikusan és transzparensen hozza létre az aktorokat.
Ez azt jelenti hogy nem szolgáltat információt azok fizikai elhelyezkedésérõl, 
tehát hogy a létrehozott \textit{Grain} aktiváció melyik szerveren helyezkedik el a klaszterben.
Az aktorok elhelyezését direkt módon nem vezérelhetjük, azonban a \textit{Placement} attribútumok
használatával egy \textit{Grain} osztályon, közvetetten befolyásolhatjuk, hová "szeretnénk", 
hogy az új aktiváció kerüljön. 

Az Orleans jelenleg 3 fajta elhelyezési (\textit{Placement})
stratégiát támogat: 
\textit{aktivációk száma alapján} történõ elhelyezés (\textit{ActivationCountBasedPlacement}), 
\textit{lokális} elhelyezés (\textit{LocalPlacement}), 
valamint \textit{véletlenszerû} elhelyezés (\textit{RandomPlacement}). A véletlenszerû elhelyezés 
használatával az összes szerverre egyenlõ valószínûséggel kerül az új aktiváció. Lokális elhelyezés
során az aktivációt kérõ \textit{Grain} szerverére történik az elhelyezés. Ha az aktiváló nem egy 
\textit{Grain}, hanem a kliens volt, ennek az elhelyezési stratégiának nincs hatása, és a 
\textit{RandomPlacement} stratégia alapján kerül az új aktiváció elhelyezésre. Az aktivációk száma alapján
történõ elhelyezés a legkevesebb aktivációval rendelkezõ szerverre helyezi el a 
kért \textit{Grain} aktivációt.

\subsection{Orleans projektek felépítése} \label{subs:orleansProjects}
Egy Orleans alkalmazást 3 fõ komponens épít fel: \textit{Aktorok} (\textit{Grains}), 
\textit{Aktor interfészek} (\textit{Grain Interfaces}) valamint a \textit{Kliens} (\textit{Client}). Ezek a komponensek 
különálló alprojektekként jelennek meg a rendszerben.

A \textit{Grain Interfaces} komponensben definiálhatjuk a projektben használt aktorokat, 
valamint ezek metódusait és a metódusok szignatúráját. Csak az itt definiált aktor típusok lesznek késõbb
felhasználhatóak, melyek implementációját a \textit{Grains} komponens tartalmazza.

A \textit{Client} komponens köti össze a külvilágot a rendszerrel, tulajdonképp egy belépési pont
az Orleans környezetbe. A kliens rendelkezhet \textit{Grain} referenciákkal, 
valamint üzenetet is küldhet \textit{Grain}-eknek. A megfelelõ kommunikáció érdekében a \textit{Client}
illetve a \textit{Grains} komponensnek is rendelkeznie kell ugyanazzal a \textit{Grain Interfaces} komponenssel.


\subsection{Alkalmazási lehetõségek}
Az Orleans környezet alapvetõen a \textit{Szolgáltatás-orientált architektúra} jegyében épült alkalmazások fejlesztését
támogatja - egymástól teljesen izolált, önálló szervizek összessége, melyek jól skálázódnak, és egy meghatározott 
mûvelet elvégzésére képesek. Egy komplex alkalmazás több száz, vagy akár több ezer szervizbõl is állhat, és a szervizek
száma az alkalmazás terheltségének változásával dinamikusan nõhet, illetve csökkenhet.
A szervizek tipikusan nem komplex, mûveletigényes számítások elvégzésére alkalmasak, fõ szempont a reszponzivitás. 

Ennek megfelelõen az Orleans aktorok egymástól izolált egységek, melyek nem osztanak meg memóriát egymással,
az egyedüli kommunikációs lehetõség közöttük az aszinkron üzenetküldés. Egy számítási szállal rendelkeznek, és 
alapértelmezés szerint az aktor entitás egyszerre csak egy üzenetet dolgozhat fel, a többi beérkezõ üzenet blokkolódik.
Mivel az aktorok virtuálisak, így a futtatókörnyezet az skálázást a terhelésnek és a rendelkezésre álló 
erõforrásoknak megfelelõen alakíthatja.

\subsubsection{Térinformatikai alkalmazás}
A dolgozat által vizsgált feladat számos ponton különbözik a fent felsorolt szempontoktól - távérzékelt adatok
feldolgozásához gyakran hatalmas méretû adatokkal kell dolgoznunk, a mûveletek költségesek, és akár több 
órát is igénybe vehetnek, valamint a mûveletek legtöbbjének párhuzamosítása esetén az egyes folyamatoknak más
folyamatok adataihoz is hozzá kell férniük. A dolgozat része volt ezen szempontbéli különbségek kiküszöbölése
a megfelelõ eredmény érdekében - a késõbbi fejezetekben az alkalmazott megoldások és az eredmények
részletesen is tárgyalásra kerülnek.

Az Orleans térinformatikai kiegészítéséhez szükséges volt egy olyan keretrendszer integrációja és felhasználása,
amelynek segítségével egységesen kezelhetünk és dolgozhatunk fel téradatokat. Így esett a választás az \textit{AEGIS}
keretrendszerre, mely a következõ fejezetben kerül tárgyalásra.

% ------------------------------------------------------------------------------

\chapter{Az AEGIS térinformatikai keretrendszer} \label{ch:aegis}
Az \textit{AEGIS} keretrendszer \textit{Eötvös Loránd Tudományegyetem Informatikai Karán} jelenleg is fejlesztés alatt
álló térinformatikai keretrendszer, melynek fõ célja térinformatikai algoritmusok, megoldások \textit{kutatás}a és \textit{fejlesztés}e.
A rendszer téradatok széles spektrumát támogatja, például: \textit{vektoros adathalmazok}, \textit{raszter felvételek}
valamint \textit{pontfelhõk}. A keretrendszer egy platformfüggetlen osztálykönyvtár, melynek fejlesztése \textit{C\#} nyelven
történik, alapja a \textit{.NET keretrendszer}, illetve a \textit{Mono Framework\footnote{http://www.mono-project.com/}}. A fejlesztés a komponens alapú
architektúra jegyében történik, mely lehetõséget ad a rendszer bõvítésére, valamint az újrafelhasználhatóságra.
Ennek segítségével az egyes komponensek könnyedén integrálhatóak más alkalmazásokba\cite{aegis}.
Mindezek mellett az AEGIS keretrendszer rendelkezik azokkal a távérzékelt adatfeldolgozó
mûveletekkel, amelyek a dolgozatban kutatásra kerültek. Ezek alapján a rendszer megfelelõ környezetet
biztosított az Orleans térinformatikai kiegészítésére.

Az AEGIS keretrendszert felépítõ fõbb komponensek: \textit{Core, IO, Operations, Temporal}.
A \textit{Core} komponens a rendszer adatmodellével kapcsolatos osztályokat tartalmazza, az \textit{IO} 
téradatok betöltéséért és írásáért felel (pl.: \textit{Shapefile}\cite{shapefile} vagy \textit{GeoTIFF}\cite{geotiff} formában),
az \textit{Operations} komponens tartalmazza a téradatokon végezhetõ mûveleteket, valamint ezek futtatókörnyezetét,
a \textit{Temporal} komponens pedig az adatmodell kiterjesztése idõbeliség kezelésével.

%\begin{figure}[ht!]
%	\centering
%	\includegraphics[width=90mm]{figures/aegis_components.jpg}
%	\caption{Az \textit{AEGIS} rendszer komponensei
%	\label{fig:aegis_components}}
%\end{figure}

\section{Adat-, illetve mûveleti modell}
A rendszer adatmodellje az \textit{Open Geospatial Consortium (OGC)} szervezet által definiált
\textit{Simple Feature Access (SFA)}\cite{sfa} szabvány. A szabványban az összes
ábrázolható alakzat közös õse a \textit{Geometry} osztály, mely a térbeli tulajdonságokat, 
és az egyes térbeli objektumok 
között elvégezhetõ mûveleteket definiálja. Az eredeti adatmodell két-, illetve háromdimenziós vektoros 
adatok tárolására koncentrál, idõbeliség nélkül. Az egyes mûveletek egységes alkalmazhatósága érdekében
az implementáció során a szabvány kiterjesztésre került raszteres adatok támogatásával is, így a 
\textit{Raster} osztály a \textit{Geometry} leszármazottja.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.9\textwidth, justification=centering}
	\includegraphics[width=120mm]{figures/aegis_data_model_extensions.png}
	\caption{Az \textit{AEGIS} adatmodellje és kiterjesztése raszteres támogatással
		\label{fig:aegis_data_model}}
\end{figure}
 
Az \textit{Operations} komponensben implementált algoritmusok kezelése is egységes alapon történik, minden mûvelet
közös õse az absztrakt \textit{Operation} osztály. A mûveletek rendelkeznek egy leíró 
osztállyal is (\textit{OperationMethod}), melynek segítségével kategorizálhatjuk a 
metódusokat, valamint optimalizálhatjuk a végrehajtást.
A mûveletek paramétereinek objektuma az \textit{OperationMethodParameter}, amely tartalmazza a paraméter típusát,
valamint értékét (\ref{fig:aegis_operations}. ábra).

A mûveletet az Operation osztály \textit{Execute()} metódusával futtathatjuk. Az \textit{Execute()} metódus
futása során rendre három alfüggvényt hív meg, ezek: \textit{PrepareResult(), ComputeResult(), FinalizeResult()}.
A \textit{PrepareResult()} a számításokhoz elõállítja a kiinduló adathalmazt, a \textit{ComputeResult()} a tényleges 
számításokat hajtja végre, a \textit{FinalizeResult()} metódus pedig összegzi és véglegesíti az eredményt.
A leszármazott osztályok ezen metódusok felüldefiniálásával határozhatják meg a mûvelet mûködését.

\begin{figure}[h!]
	\centering
	\includegraphics[width=150mm]{figures/aegis_processing.png}
	\caption{Az \textit{AEGIS} mûveleti modellje
		\label{fig:aegis_operations}}
\end{figure}

Minden térbeli mûvelet, amely vektoros
adatokra definiált (\textit{metszet, projekció}), alkalmazható raszteres felvételekre is.
A csak raszteres adatokon futó mûveleteket (\textit{szûrés, küszöbölés, hisztogram-transzformáció})
pedig olyan metaadattal látjuk el, amely megakadályozza a vektoros adathalmazon történõ futtatást.
Ezek a raszteres mûveletek az \textit{Operations} komponens \textit{Spectral} kiterjesztésében
helyezkednek el. A dolgozat során az itt implementált mûveletek kerültek felhasználásra.

\section{Feldolgozás Hadoop architektúrán}
Az AEGIS támogatja a \textit{Hadoop} architektúrával történõ adatkezelést, illetve feldolgozást.
A rendszer megfelelõen kezeli nagyméretû bináris adatok \textit{HDFS}-be történõ beolvasását (pl.: \textit{GeoTIFF} formában).
Az input adat opcionálisan particionálható, az egyes partíciók így elosztottan is feldolgozhatók (A fent említett
\textit{Operations} komponensben definiált mûveletek módosítás nélkül alkalmazhatók Map-, illetve Reduce függvényekként).

A keretrendszer Hadoop támogatása jelentõsen megkönnyítette a dolgozat során vizsgált mûveletek
teljesítményének összevetését az Orleans keretrendszerrel. A Hadoop rendszerhez
nem volt szükséges külön térinformatikai keretrendszer felhasználása, így az architektúrából adódó teljesítménybeli
differenciák sem jelennek meg az eredményekben. 

% ------------------------------------------------------------------------------

\chapter{Megvalósítás} \label{ch:application}
A dolgozat célja az Orleans rendszer távérzékelt felvételek feldolgozására való kiterjesztése és
a gyakorlatban való alkalmazhatóságának vizsgálata. 
Ehhez szükséges volt egy olyan prototípus alkalmazás megvalósítása, 
melynek segítségével tesztelhetõek az Orleans rendszer képességei távérzékelt felvételek feldolgozásában. 
Ezen fejezet célja az alkalmazás felépítésének és komponenseinek bemutatása.

A dolgozat során elkészített prototípus alkalmazás (\textit{OrleansSpectral}) felépítése hasonló a 
tradicionális Orleans alkalmazásokhoz, rendelkezik a \ref{subs:orleansProjects}. szakaszban említett
három komponenssel (\textit{Grains}, \textit{Grain interfaces}, \textit{Client}), valamint ezeken túl 
egy \textit{Common} projekttel, amely az egyes komponensek mindegyike
által használt osztályokat és mûveleteket tartalmazza.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=130mm]{figures/orleansSpectralComponents.png}
	\caption{Az alkalmazás komponensdiagramja \label{fig:orleansSpectralComponents}}
\end{figure}

\section{Az AEGIS keretrendszer integrációja}
Távérzékelt felvételek feldolgozásához szükség volt egy egységes téradatmodellre,
a felvételek beolvasására, a végrehajtandó mûveletekre, illetve az eredmények lemezre történõ kiírására.
Ennek megfelelõen az \textit{AEGIS} keretrendszer \textit{Core, IO}, valamint \textit{Operations} komponenseire volt
szükség, ezek kerültek integrálásra. Mivel mindkét rendszer a \textit{.NET} keretrendszerre épül, 
így az integráció is egyszerû volt, csupán az AEGIS által nyújtott \textit{.NET szerelvények} 
(\textit{assembly}) referálására volt szükség a fent felsorolt projektekben.

\section{Input adatok particionálása és feltöltése} \label{sec:partitioning}
A \ref{ch:remoteSensingAnalysis}. fejezetben említésre került, hogy távérzékelt felvételek
elosztott feldolgozásánál az input adatokat valamilyen tulajdonság alapján feldarabolunk
és az egyes darabokat külön számítási egységekkel dolgozunk fel. Az Orleans rendszer
esetén is ez történt, azonban a particionálás mûvelete kiegészült egy 
\textit{partíció leíró} fájl generálásával, amely tartalmazza az eredeti kép dimenzióit,
az egyes darabok elhelyezkedését és kiterjedését az eredeti képhez képest, a fájlok fizikai elérési útvonalát,
valamint további metainformációkat (pl: a particionáláshoz használt algoritmus). 
Ezen felül a leíró fájl tartalmazza az 
eredeti kép \textit{hisztogram-értékei}t, ez az információ késõbb felhasználható az egyes mûveletekben.
A leíró fájl segítségével könnyedén meghatározható, hogy a kép egy darabja hol foglal helyet az eredeti képen.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=150mm]{figures/partitionDescriptor.png}
	\caption{Az input egy lehetséges particionálása és a partíció leíró fájl \label{fig:partitionDescriptor}}
\end{figure}


Mivel a Hadoop \textit{HDFS} rendszerrel ellentétben az Orleans keretrendszer nem definiál saját elosztott
fájlrendszert, így a feldarabolt kép darabjainak szétosztása manuálisan történik a klaszterben. Az egyes darabokat
fel kell töltenünk a feldolgozó egységekre, és az elérési útvonalukat 
rögzítenünk kell a partíció-leíróba.

\section{Adatok feltérképezése, azonosítása és beolvasása}
Az adatok elhelyezése után az õket feldolgozó aktorok létrehozása következik.
A megfelelõ teljesítmény érdekében minden partíciót külön aktor fog feldolgozni.
Ehhez szükséges tudnunk, mely szerveren hány fájlpartíció helyezkedik el, és ezek mindegyikére
létrehozni egy aktor entitást. 

Mint korábban említésre került, direkt módon nem határozhatjuk meg az aktorok elhelyezését a
klaszterben, azonban az elhelyezési stratégiát befolyásolhatjuk a \textit{Placement} attribútumokkal.
Sajnos jelenleg a rendszer nem tartalmaz olyan \textit{Placement} stratégiát, amellyel meghatározott mennyiségû
Grain-t tudnánk létrehozni az összes szerveren (Az \textit{ActivationCountBasedPlacement} áll
legközelebb a feladathoz, azonban ez a stratégia fõként nagyobb klaszterek esetén tud hatékony lenni
a dolgozat során nem produkált használható teljesítményt).

A fenti limitációk megkerülése érdekében egy saját stratégia került alkalmazásra - bevezetünk egy
"\textit{manager}" aktort (\textit{OperationManagerGrain}), 
melyet a \textit{RandomPlacement} attribútummal látunk el. A \textit{manager}
aktorból addig hozunk létre új aktivációkat, amíg a klaszter minden szerverén legalább egy létre nem jön
(alapértelmezés szerint az aktort hosztoló szerver identitása is transzparens az alkalmazás számára, 
azonban ez az információ a Grain-ek identitásából visszafejthetõ).

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=110mm]{figures/getOneGrainFromEachSilo.png}
	\caption{Minden szerverrõl egy menedzser aktor aktiválása \label{fig:getOneGrainFromEachSilo}}
\end{figure}

Mivel a véletlenszerû elhelyezés közel normális eloszlású, és mivel az aktorok létrehozása nem költséges
mûvelet, így ez a fázis nem okoz teljesítményromlást a feldolgozásban. 
A létrehozott aktorok közül minden szerverrõl egyet választunk, ez lesz a szerver "menedzsere". 

A menedzser entitás nem végez spektrális mûveleteket, hanem a mûveleteket feldolgozó aktorok 
példányosításáért és a kliensnek való továbbításáért felel. Egy elõkészítési fázisban
minden menedzser Grain feltérképezi a szerverén lévõ feldolgozandó fájldarabokat
(a partíció leíróban megadott útvonalon), és ennek megfelelõ mennyiségû feldolgozó Grain-t
(\textit{SpectralOperationGrain}) példányosít. A \textit{SpectralOperationGrain}-t a \textit{LocalPlacement}
attribútummal látjuk el, így minden új aktiváció az õt példányosító menedzser alkalmazás szerverén
fog létrejönni. A létrehozott Grain-eket ezután hozzárendeljük a feltérképezett fájldarabokhoz.
Így szerver szinten minden entitásról tudjuk, hogy melyik fájldarabot dolgozza fel. 

\begin{figure}[H] 
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=155mm]{figures/grainsClassDiagram.png}
	\caption{\textit{Grain}ek osztálydiagramja \label{fig:grainClassDiagram}}
\end{figure}

Azonban a megfelelõ
kommunikáció érdekében minden szerveren minden Grain-nek tudnia kell az összes fájldarabról, és annak
elérhetõségérõl. Ehhez minden menedzser továbbítja a szerveren lévõ feldolgozó Grain-ek 
identitását és a hozzá tartozó fájldarabokat a kliensnek (erre egy dedikált Grain is definiálható
lett volna, azonban a feldolgozó aktorokkal való direkt kommunikációhoz egyébként is szükséges
továbbítani az identitásukat a kliensnek). A kliens a korábban említett partíció leíróban kiegészíti
az összes fájldarabra vonatkozó információt a feldolgozó Grain-ek identitásával. 
Ezután elküldi a kiegészített leíró fájlt ezeknek az aktoroknak.

\begin{figure}[H] 
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=155mm]{figures/discoverParts.png}
	\caption{Input darabok feltérképezése, és a Grain-ek informálása \label{fig:discoverParts}}
\end{figure}

\section{Mûveletek futtatása}
A mûveleteket végzõ aktorok létrehozása és megfelelõ információval való ellátása után következik a 
kívánt mûvelet végrehajtása. A mûveletek indítása már nem a menedzser Grain-en keresztül történik, a kliens
direkt módon a feldolgozó Grain-ekkel kommunikál. A mûveletet, valamint paramétereit az alkalmazás indításánál
paraméterekként adhatjuk meg, ezeket az információkat kapja meg a \textit{ComputeOperation} mûvelet.
A \textit{FinalizeOperation} mûvelet felel az eredmények lemezre történõ kiírásáért, és csak akkor hajtódik végre,
ha mindegyik Grain-en befejezõdött a ComputeOperation. Ez azért szükséges, mert egy Grain hamarabb
végezhet mint a többi, azonban az általa tárolt adatokra szüksége lehet a többi Grain-nek. A mûvelet futtatásának
eredményét a \textit{GetOperationResult} metódussal kérdezhetjük le az egyes Grain-ektõl. A visszaadott
információ tartalmazza a mûvelet \textit{eredmény}ét (\textit{Futtatásra kész, Fut, Sikeres, Hibás}), 
a futás alatt \textit{eltelt idõ}t, valamint - ha a futás során hiba történt - a fellépõ \textit{kivétel}t.


\chapter{Vizsgált algoritmusok} \label{ch:algorithms}
Az Orleans felépítésének és kiterjesztésének bemutatása után a dolgozat során vizsgált algoritmusok
ismertetése következik. Az elemzett mûveletek megválasztásánál fontos szempont volt a sokszínûség - 
a távérzékelt felvételek feldolgozásának mindkét fázisából (tehát az elõfeldolgozás és a tematikus 
osztályozás fázisból), mindegyik munkaterület-csoportból kerültek kiválasztásra
mûveletek, ezáltal átfogó képet kaphatunk, a feldolgozás mely részein alkalmazható hatékonyan a rendszer.

Az egyes mûveletek kiterjesztése az Orleans platformra munkaterület-csoportonként különbözõ megközelítést igényelt,
így a bemutatás az egyes csoportokon végighaladva történik, ismertetve a mûveletek mellett az alkalmazott
ötleteket, és megvalósításukat.


\section{Lokális mûveletek}
Elosztott feldolgozás szempontjából a legegyszerûbb munkaterület-csoport a lokális mûveletek csoportja.
Ebben az esetben az input kép tetszõleges módon particionálható, és elosztottan feldolgozható, nem szükségesek
további lépések. A lokális mûveletek egyszerûségük miatt megfelelõ alapot nyújtottak a vizsgált rendszer alapvetõ
lehetõségeinek megismerésére, melyre a késõbbiekben építkezni lehetett. Ezen felül a lokális 
mûveletek segítségével 
a rendszer mûködtetésének a mûveletek futtatásán túli költsége (Grain-ek létrehozása, adatok feltérképezése és
beolvasása) is mérhetõ volt, így kevésbé számításigényes 
algoritmusok kerültek tesztelésre.

\subsubsection{Spektrális Invertálás}
A \textit{spektrális invertálás} egy egyszerû lokális \textit{látványjavító mûvelet}, melynek során az egyes 
intenzitásértékeket "megfordítjuk" a felvétel minden egyes képpontjának minden sávjára. 
Ezt úgy érhetjük el, hogy a radiometriai felbontás maximálisan felvehetõ értékébõl kivonjuk az intenzitásértékeket.
A \ref{subs:remoteSensingBasics}. szakaszban bemutatott jelölést felhasználva a mûvelet
matematikailag a következõképpen ábrázolható: Egy \textit{N} sorból és \textit{M} oszlopból álló, 
\textit{B} spektrális sávval rendelkezõ \textit{V} digitális felvételbõl az 
alábbi \textit{V'} digitális felvétel áll elõ:

\begin{center}
	$
	V' = 
	\begin{pmatrix}
	\vec{v'}_{11} & \cdots & \vec{v'}_{1\textit{M}} \\
	\vdots  & \ddots & \vdots  \\
	\vec{v'}_{\textit{N}1} & \cdots & \vec{v'}_{\textit{NM}} 
	\end{pmatrix}
	$,
\end{center}
\begin{center}
melynek minden $b \in [1\hdots B]$ spektrális sávjára:
\end{center}
\begin{center}
$v'_{\textit{ijb}} = H - v_{\textit{ijb}}$,
\end{center}
ahol \textit{H} a \textit{V} vektor radiometriai felbontásának maximálisan ábrázolható értéke.

%egyes elemeinek intenzitásvektora: 
%$\vec{v}_{\textit{ij}} = (v_{\textit{ij}1}, \hdots, v_{\textit{ijB}})$, ahol minden $b \in [1\hdots B]$ elemre
%$v_{\textit{ijb}} \in [\textit{1}\hdots\textit{H}]$.
%$v'_{\textit{ijb}} = H - v_{\textit{ijb}}$.

\subsubsection{ToA-Reflektancia}
A \ref{ssn:preProcessing}. szakaszban ismertetett \textit{ToA-Reflektancia} a \textit{radiometriai korrekció}k 
közé tartozó lokális
mûvelet, melynek célja a földfelszín tényleges visszaverésének kiszámítása 
a légköri zavaró hatások figyelembe vétele nélkül.
A ToA-Reflektancia kiszámításának módja felvételtípusonként változik, és a szükséges
paraméterek általában \textit{metaadat}ok formájában a felvételekkel együtt kerülnek publikálásra.
Az egyik legnépszerûbb mai távérzékelt felvételeket szolgáltató mûholdcsalád, a 
\textit{Landsat}\footnote{http://landsat.usgs.gov/} mûholdak által szolgáltatott felvételekre 
a reflektancia kiszámítása az alábbi módon történik:

Elsõ lépésként a spektrális radianciát kell kiszámolnunk, mely a digitális számokkal legtöbbször lineáris kapcsolatban
áll. Kiszámításához két paraméter szükséges a 
pixel digitális értékén(\textit{DN}) kívül: az \textit{emelkedés} (\textit{gain}) 
valamint az \textit{eltolás} (\textit{offset}). A paraméterekbõl képezve az $L_\lambda$ spektrális 
radiancia képlete a következõ:
\begin{center}
$L_\lambda = gain * DN + \textit{offset}$
\end{center}

A ToA-Reflektancia a radianciából számítható, figyelembe véve a \textit{Nap}, a \textit{felvételezett terület}
és a \textit{szenzor} elhelyezkedését egymáshoz képest. Matematikai formában a következõképpen írható fel a $P_\lambda$-val
jelölt reflektancia:

\begin{center}
	$P_\lambda	= \pi * L_\lambda * d^2 / E_\lambda * cos\theta_s$
\end{center}

Ahol $d$ a Nap és a Föld távolsága csillagászati egységben, $E_\lambda$ a 
\textit{légkörön kívüli irradiancia (az adott hullámsávban beesõ napsugárzás intenzitása)} átlaga, 
$\theta_s$ pedig a \textit{zenitszög (a földdarabra érkezõ napsugárzás beesési szöge)}\cite{toarefCompute}.

\subsubsection{Konstans küszöbölés}
A \textit{konstans küszöbölés} a küszöbölõ algoritmusok legegyszerûbb formája. Egy darab spektrális sávot tartalmazó
képre elvégezve
a küszöbölés eredménye egy olyan bináris kép, ahol az egyes képpontok két kategóriába tartozhatnak.
Azt, hogy melyik kategória felel meg egy adott képpontnak, az alapján határozzuk meg, 
hogy intenzitása alacsonyabb vagy magasabb a megadott \textit{konstans küszöb}értéknél. A szokásos jelöléssel egy
\textit{N} sorból és \textit{M} oszlopból álló \textit{V} mátrixra és egy \textit{K} konstans küszöbértékre 
alkalmazott küszöbölés eredménye egy 

\begin{center}
	$
	V' = 
	\begin{pmatrix}
	v'_{11} & \cdots & v'_{1\textit{M}} \\
	\vdots  & \ddots & \vdots  \\
	v'_{\textit{N}1} & \cdots & v'_{\textit{NM}} 
	\end{pmatrix}
	$,
\end{center}
\begin{center}
mátrix, melynek minden $v'_{ij}$ elemére $v'_{ij} \in \mathbb{L}$ és
\end{center}
\begin{center}
	$
	v'_{ij} = 
	\begin{cases}
		1 & \quad \text{ha } v'_{ij} \geq K	 \\
		0 & \quad \text{ha } v'_{ij} < K \\
	\end{cases}
	$
\end{center}

\section{Fokális mûveletek}
\textit{Fokális mûveletek} végrehajtása esetén egy pixel kiszámításához szükség van a pixel egy
meghatározott sugarú környezetének értékeire. A szükséges terület méretét a mûvelet elindításának
pillanatában ismerjük, és a futás során ez az információ nem változik.

\subsubsection{Input adatok particionálása fokális mûveletek esetén}
A particionálás során két lehetõségünk van: vagy már elõzõleg figyelembe vesszük,
hogy várhatóan mekkora területre lesz szüksége az egyes mûveleteknek és ez alapján a partíciókat
\textit{átfedések}kel hozzuk létre - ekkor a mûvelet indításakor biztosítanunk kell, hogy a
mûvelet által igényelt terület méreténél nagyobb, vagy egyenlõ a felhasznált partícióra definiált átfedés.

Egy másik lehetõség - ha a partíciók nem rendelkeznek átfedésekkel,
hogy a feldolgozás során a szükséges intenzitásértékeket a feldolgozó egységek egymás
számára elérhetõvé teszik. Ekkor, ha egy egységnek egy olyan értékre van szüksége,
amelyet egy másik feldolgozó egység birtokol, akkor ezt az értéket futás során "elkérheti"
a birtokló folyamattól.
Ezzel a megoldással valószínûleg nem érhetõ el olyan teljesítmény, mint
ha az összes adat lokálisan rendelkezésre állna, cserébe viszont a partíciók mérete nem nõ.
További finomítási mód lehet például, ha a folyamatok egyszerre nem csak egy-egy koordináta 
intenzitás-értékeit kérik el, hanem meghatározott méretû blokkokat. Ebben az esetben csökken a
hálózati kommunikációk száma, azonban növekszik a hálózaton átküldött adatok mérete.

\subsection{Szûrések}
A fokális mûveletekre talán a legjobb példa a különbözõ \textit{szûrések} alkalmazása. Szûréseket a képfeldolgozás
számos területén alkalmazhatunk, például: \textit{éldetektálás, simítás, elmosás, élesítés}. A szûrõ mûveletek
során az eredmény pixelértékét a kép minden egyes pixelére az õt valamilyen sugárban körülvevõ értékek súlyozott átlaga adja.
Az egyes súlyokat legtöbbször egy \textit{kernelmátrix}  segítségével definiáljuk - ezzel megadható, hogy a környezet 
pixelei milyen módon számítanak bele az eredménybe. Például az inputkép minden pixelét változatlanul hagyó szûrõ
kernelmátrixa az alábbi:
\begin{center}
	$
	\begin{bmatrix}
	0 \quad 0 \quad 0 \\
	0 \quad 1 \quad 0 \\
	0 \quad 0 \quad 0 \\
	\end{bmatrix}
	$
\end{center}

A kernelmátrix középsõ értéke az aktuális pixel-, a többi értéke pedig az õt körülvevõ pixelek súlya.

\subsubsection{Átlagoló szûrõ}
Az \textit{átlagoló szûrõ (box filter)} egy egyszerû lineáris szûrõ, amelynek eredményeként minden pixel értéke az 
õt meghatározott sugárban körülvevõ input pixelek értékének súlyozatlan átlaga, tehát a kernelmátrixa a következõképpen
írható fel: 

\begin{center}
	$
	\begin{bmatrix}
	1 \quad 1 \quad 1 \\
	1 \quad 1 \quad 1 \\
	1 \quad 1 \quad 1 \\
	\end{bmatrix}
	$
\end{center}

Az átlagoló szûrõ használatával elérhetjük a kép simítását, valamint
egy bizonyos számú iterációban egymás után alkalmazva közelíti a \textit{Gauss szûrõ}t.

\subsubsection{Gauss szûrõ}
A \textit{Gauss szûrõ (Gaussian blur)} egy széles körben használt szûrõ a grafikus képfeldolgozás 
területén, legfõképp a kép zajosságának csökkentésére és a részletesség redukálására használatos.
A Gauss szûrõ alkalmazása során a képet egy \textit{Gauss függvény} segítségével
mossuk el, tehát a szûrõ kernelmátrixában egy kétdimenziós \textit{Gauss-eloszlás} értékei szerepelnek\cite{gaussianBlur}.
Egy $0$ várható értékû, $\sigma$ szórású Gauss-eloszlás a következõképpen írható fel:

\begin{center}
$
		G(x, y) = \frac{1}{\sqrt{2\pi\sigma^2}}
		e^{-\frac{x^2 + y^2}{2\sigma^2}}
$
\end{center}

A kernelmátrixot a fenti Gauss-eloszlás segítségével állíthatjuk elõ, ekkor az $x$ és az $y$ értékek a kernelmátrix
középpontjától számított távolságok a horizontális-, illetve a vertikális tengely mentén. 

\subsubsection{Gabor szûrõ}
A \textit{Gábor Dénes} után elnevezett \textit{Gabor szûrõ (Gabor filter)}\cite{gaborFilter}
egy fõleg éldetektálásra használt lineáris szûrõ. 
A szûrõ mûködési elve közel áll az emlõsök látórendszeréhez, ezért különösen 
hatékony a vizuális képfeldolgozás területén\cite{gaborFilter2,gaborFilterApplications} (\textit{éldetektálás}, \textit{írott és nyomtatott szöveg felismerése}, 
\textit{arcfelismerés}).

A Gabor szûrõ tulajdonképpen egy Gauss függvény modulálása egy szinusz síkhullámmal (\ref{fig:gaborFilterModulation}. ábra), mely a következõképpen írható fel matematikai formában:

\begin{center}
	$
	G_{\lambda,\theta,\varphi,\sigma,\gamma}(x, y) = e^{-\frac{{x'}^2+\gamma^2{y'}^2}{2\sigma^2}} * cos(2\pi\frac{x'}{\lambda} + \varphi)
	$
\end{center}
\begin{center}
	ahol
\end{center}
\begin{center}
	$
	x' = x*\cos\theta + y*\sin\theta \quad \text{és} \quad y' = -x*\sin\theta + y*\cos\theta 
	$
\end{center}
A függvény paraméterei a következõk: $\lambda$ a szinuszhullám hullámhossza, $\theta$ az orientációja, $\varphi$ az eltolása, $\sigma$ a Gauss függvény szórása, $\gamma$ pedig a nagysága, kiterjedése.
\begin{figure}[H]
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.95\linewidth]{figures/gaussian.png}
		\caption{}
		\label{fig:gaussian}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.95\linewidth]{figures/sinusoid.png}
		\caption{}
		\label{fig:sinusoid}
	\end{subfigure}
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=.5\linewidth]{figures/gaborFilter.png}
		\caption{}
		\label{fig:gabor}
	\end{subfigure}
	\captionsetup{justification = centering}
	\caption{A (\subref{fig:gabor}) Gabor függvény  elõállítása az (\subref{fig:gaussian}) Gauss függvénybõl és a (\subref{fig:sinusoid}) szinusz hullámból \cite{gaborFilterVisualisation}}
	\label{fig:gaborFilterModulation}
\end{figure}

A Gabor szûrõ kernelmátrixát a Gauss szûrõhöz hasonlóan számíthatjuk, $x$ és $y$
a kernelmátrix középpontjától számított távolságok a horizontális- illetve a vertikális
tengely mentén.

\subsection{Fokális mûveletek feldolgozása az Orleans rendszerben}
A fokális mûveletek elosztott feldolgozása során az egyes partíciók legtöbbször meghatározott mennyiségû plusz 
adatot igényelnek
szomszédaiktól. Ez a legtöbbször megoldható a korábban ismertetett átfedések definiálásával, mivel
a mûveletek futtatásánál ellenõrizni tudjuk, hogy elegendõ plusz terület áll-e rendelkezésre a végrehajtáshoz.
A Hadoop alapú feldolgozás ezt a megoldást használja, és az Orleans rendszer is felkészült a plusz területtel rendelkezõ
adatok feldolgozására, azonban a \textit{Grain}-ek egymás közti \textit{direkt kommunikáció}ján alapuló feldolgozás is
implementálásra került annak érdekében, hogy megfelelõ képet kaphassunk, a kétfajta megközelítés közül melyik elõnyösebb
a távérzékelt felvételek feldolgozása kapcsán.

\subsubsection{Virtuális Raszter}
Az AEGIS rendszerben megvalósított metódusok jelenleg egy konkrét raszter kép minden pixelét feldolgozzák, nincs lehetõség
annak meghatározására, hogy mûvelet a kép csak egy részterületén dolgozzon. Emiatt ha a képet átfedés nélkül 
feldaraboljuk és az eredeti mûveleteket végrehajtjuk, azok az egyes partíciók szélén nem fognak helyes eredményt adni,
mivel a mûveletnek nincs információja arról, hogy az adott partíció egy nagyobb kép része és a szélén lévõ pixelek kiszámításához
szükséges lehet további adat felhasználása is.

A fenti probléma kétféleképpen volt orvosolható. Az egyik lehetõség a mûveletek teljes újraírása és adaptálása
az Orleans környezetbe, így a módosított mûveletek a partíció abszolút pozíciója alapján futottak volna, és a 
szükséges helyeken (a partíciók szélein) kezelték volna az esetleges Grain kommunikációt, ezáltal a szükséges
plusz adatok beszerzését. Azonban ez a megoldás több szempontból is kedvezõtlen volt. Egyrészt az összes
mûvelet módosítása már önmagában is jelentõs ráfordítással járt volna, így a keretrendszer által 
nyújtott elõnyök nagy része nem lett volna kihasználható. Másrészt a jövõben implementálásra kerülõ mûveletek 
adaptációja is elkerülhetetlen lett volna.

Az AEGIS keretrendszer fejlesztésekor azonban fontos szempont volt a rugalmasság és a bõvíthetõség. 
Ennek megfelelõen minimális beavatkozással az AEGIS keretrendszerbe és mûveleteibe, lehetõség volt
a modell kiterjesztésére és ez által a fenti probléma megfelelõ kezelésére. Ehhez bevezetésre került egy 
\textit{virtuális raszter} osztály (\textit{VirtualRaster}), amely az eredeti kép dimenzióival rendelkezik, 
és egy \textit{szerviz}en keresztül éri el az egyes adatokat. A szerviz (\textit{OrleansRasterService}) 
inputja az aktuálisan feldolgozandó képdarab, a darabok azonosítására szolgáló \textit{partíció leíró}, 
valamint a feldolgozásban részt vevõ összes \textit{Grain} elérési adatai. 

A mûveletek kizárólag a szervizen keresztül férnek hozzá a raszter adatokhoz, és az eredeti kép abszolút
koordinátáival dolgoznak. Így ha a mûveletnek szüksége van egy pixelértékre, a szerviz a rendelkezésre álló
partíció leíró alapján el tudja dönteni, hogy a szükséges érték lokálisan rendelkezésre áll-e,
vagy távoli elérés szükséges hozzá. Ha lokálisan rendelkezésre áll, a szerviz 
úgyszintén a \textit{partíció leíró} alapján az \textit{abszolút} koordinátákat 
a lokális partíció \textit{relatív} koordinátáivá konvertálja, és a relatív pozíción szereplõ adatot
szolgáltatja a mûveletnek. Ellenkezõ esetben szükséges megkeresni azt a Grain-t, amely a koordinátát
tartalmazó partíciót dolgozza fel, és egy aszinkron üzenetben elkérni a szükséges adatot. 
Ezzel a megoldással bármelyik Grain entitás által végrehajtott mûvelet képes hozzáférni az input kép bármely pixelértékéhez.

\begin{figure}[H] 
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=100mm]{figures/virtualRaster.png}
	\caption{A virtuális raszter felépítése és mûködése \label{fig:virtualRaster}}
\end{figure}

Ahhoz hogy a lokális adatokhoz más Grain-ek is hozzáférjenek, A Grain interfészén biztosítanunk kell a megfelelõ metódusokat.
Ezeket a metódusokat (\mbox{\textit{ReadValue}}, \mbox{\textit{ReadFloatValue}}) az \textit{IRasterProvider} interfész tartalmazza, 
ebbõl származik a feldolgozó Grain interfésze. Az Orleans ismertetésekor említésre került, hogy az egyes fordulók
alapértelmezés szerint nem fedhetik át egymást. Ez a jelenlegi esetben problémát okozna, tekintve hogy a feldolgozás során
több távoli adatra is szükség lehet, és nagy valószínûséggel a távoli adattal rendelkezõ Grain is a mûveletet végrehajtó
fázisban áll. Ezért a feldolgozó \textit{SpectralOperationGrain} osztályt megjelöltük a \texttt{[Reentrant]} attribútummal, így a
beérkezõ kérések a mûvelet végrehajtása közben is kiszolgálásra kerülnek a Grain által.

\subsubsection{Végrehajtási terület}
Az abszolút koordináták használata miatt a mûveletek módosítás nélkül az input kép egészére futnának, nem csak a 
lokálisan elérhetõ tartalomra, ez pedig jelentõs teljesítményromláshoz vezetne. 
A probléma megoldásához az AEGIS keretrendszer minimális módosítása volt szükséges. A transzformációs mûveletek õsét, a 
\textit{SpectralTransformation} osztályt kiegészítettük egy paraméterrel, amely az adott mûvelet 
\textit{végrehajtási terület}e (\textit{Operation Area}). A végrehajtási terület definiálja azt a területet,
amelynek pixeleire szeretnénk alkalmazni a mûveletet. A mûveletnek természetesen szüksége lehet a végrehajtási területen
kívül esõ pixelekre is, ezen pixelértékeknek rendelkezésre kell állniuk a helyes eredmény érdekében. 
Az Orleans rendszerben ennek megfelelõen a mûveletek - bár az egész terület adataival rendelkeznek - 
csak a lokálisan rendelkezésre álló területen fognak végrehajtódni.

A virtuális raszter bevezetésével, valamint a mûveletek végrehajtási területtel való kiterjesztésével
megoldást adunk arra a problémára ha egy fokális mûvelet végrehajtásához
csak olyan input partíciók állnak rendelkezésre, melyek nem rendelkeznek átfedésekkel. A következõ fejezetben
a megoldás hatékonysága részletesen is tárgyalásra kerül, annyi azonban elmondható, hogy a Grain-ek hálózati kommunikációja
költséges, így a megfelelõ teljesítmény érdekében törekedni kell a kommunikációk számának minimalizálására.

\section{Regionális mûveletek}
Regionális mûveletek feldolgozása során az eredménykép minden pixelének kiszámításához az adott pixelt
körülvevõ, vele homogén pixelek régiójára van szükség. Ezeket a régiókat az egyes pixelek tulajdonsága alapján építik
fel az algoritmusok, tehát a régiók a végrehajtás során dinamikusan változnak, - a kiindulási állapottól
függõen - növekedhetnek, illetve csökkenhetnek. 

A regionális mûveletek szemléltetésére leginkább
a \textit{régió alapú szegmentáló algoritmusok} a legalkalmasabbak. 
Ezen mûveletek széles körben használatosak a távérzékelt felvételek feldolgozásában, 
a tematikus osztályozás kulcsfontosságú mûveletei.

\subsection{Szegmentálás}
A szegmentáló algoritmusok célja homogén területek összekapcsolása, \textit{szegmens}ekbe foglalása és
egységes kezelése. Egy szegmens spektrálisan hasonló, szomszédos képpontok egybefüggõ halmaza. A tematikus osztályozás
során a szegmentálás segítségével elérhetjük, hogy az eredményképen az egyes felszínborításokhoz tartozó
kategóriák kevésbé keveredjenek.

A régió alapú szegmentáló algoritmusok két fõ csoportra oszthatók. Az \textit{összevonás alapú} mûveletek 
kezdetben minden képpontot önálló szegmensnek tekintenek, és egy meghatározott számú iterációs lépésben a megadott
feltételeknek eleget tevõ szomszédos elemeket összevonják (\textit{összevonási kritérium}). 
A \textit{vágás alapú} mûveletek esetén kezdetben a teljes
felvételt egy darab szegmensnek tekintjük, melyet minden  lépésben a meghatározott 
\textit{vágási kritérium}nak megfelelõen több részre bontunk. 

\subsubsection{Negyedelõ fa alapú szegmentálás}
A \textit{negyedelõ fa} (\textit{Quadtree}) egy hierarchikus fa adatszerkezet, 
mely a sík egyenlõ régiókra történõ rekurzív felbontásán alapul. Fõként a képfeldolgozás és a számítógépes
grafika területén terjedt el, valamint térbeli adatok indexelésére és raszteres adatok tömörítésére 
is használatos.

Távérzékelt felvételek feldolgozásának területén leginkább a \textit{régió alapú} verziója használatos\cite{quadTree}, melynek
segítségével a felvételt egy megadott \textit{homogenitási kritérium} alapján régiókra bonthatunk. 
A homogenitási kritérium a fa minden csúcsára meghatározza, hogy az adott csúcsban további dekompozícióra van-e szükség, 
vagy az egyes értékek közti különbség kisebb a megadott küszöbnél, ekkor a csúcs nem kerül további felosztásra. 
A felosztást addig folytatjuk, amíg minden csúcs homogén nem lesz, tehát nem lesz szükség további vágásra.

A \textit{negyedelõ fa alapú szegmentálás} is a régió alapú negyedelõ fán alapul, itt az értékek homogenitását
az intenzitásuk közti különbségek határozzák meg. Ennek megfelelõen kétféle negyedelõ fa alapú szegmentálást 
különböztetünk meg. A \textit{felülrõl lefelé} haladó szegmentálás esetén kezdetben az egész képet egy szegmensnek
tekintünk, és erre alkalmazzuk a vágási feltételt addig, amíg minden érték homogén nem lesz. A \textit{lentrõl felfelé}
építkezõ szegmentálás esetén a kép minden pixele külön szegmensként jelenik meg, ebben az esetben vágási feltétel
helyett összevonási feltételt kell alkalmaznunk, és a szegmentáló mûvelet addig fut, amíg már egyetlen
csúcsot sem tudunk összevonni. 

%TODO Figure?

\subsubsection{Szekvenciális csatolás alapú szegmentálás}
A \textit{szekvenciális csatolás alapú szegmentálás} \cite{sequentialCoupling,sequentialCoupling2} 
(\textit{Sequential Coupling Segmentation}) egy \textit{összevonás-alapú} 
szegmentáló mûvelet, mely elméletben képes tetszõleges formájú szegmensek elõállítására, és az
inputot sorfolytonosan dolgozza fel.
Elsõ lépésként $2 \times 2$-es méretû kiinduló cellákra osztja fel az input
felvételt, majd eldönti hogy homogénnek tekinthetõk-e ezek a cellák. Egy cella homogénnek tekinthetõ, ha
a cella által tartalmazott $n$ darab pixel minden sávjának értékeire teljesül a következõ egyenlõtlenség:
%\begin{center}
$$
\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{(n-1)\bar{x}^2} \leq C_H
$$
%\end{center}

A fenti képlet azt fejezi ki, hogy a cella pixeleinek szórása minden sávban egy megadott határon belül marad 
az intenzitások átlagához képest. Az inhomogén cellák pixeleit nem soroljuk szegmensekbe, a homogén cellákat pedig
felülrõl lefelé - balról jobbra haladva megpróbáljuk valamelyik szomszédos, már feldolgozott szegmenshez csatolni. Ha az összevonás
nem lehetséges, a cella egy új szegmens kezdete lesz. 
Az összevonás akkor lehetséges, ha a szegmensekhez tartozó intenzitások szórása és átlaga 
által meghatározott \textit{ANOVA} 
(\textit{ANalysis Of VAriance - Varianciaanalízis}) kritériumok teljesülnek: 


%TODO Write down what is x_i and y_i
Legyen $x$ egy $m$ elemû, $y$ egy $n$ elemû minta, $z$ pedig a kettõ összevonásával kapott eloszlás, és legyen:
\begin{align}
A_x = \sum_{i=1}^m (x_i - \bar{x})^2 && A_y = \sum_{i=1}^n (y_i - \bar{y})^2 && A = A_x + A_y
\nonumber
\end{align}
\begin{align}
B_x = \sum_{i=1}^m (x_i - \bar{z})^2 && B_y = \sum_{i=1}^n (y_i - \bar{z})^2 && B = B_x + B_y
\nonumber
\end{align}
Két szegmens akkor vonható össze, ha az alábbi egyenlõtlenségek minden sávra teljesülnek 
adott $C_1$ és $C_2$ konstans küszöbértékekre:
\begin{align}
(A/B)^{(m+n)/2} \geq C_1 && \bigg({(A_x / m)^{m-1}(A_y/n)^{n-1} \over {(A/(m+n))^{m+n-2}}}\bigg)^{1/2} \geq C_2
\nonumber
\end{align}

Mivel az inhomogén cellákat nem soroltuk szegmensekbe, ezért ezeket a pixeleket késõbb a 
\textit{klaszterezés} során kell a nekik megfelelõ tematikus osztályokba sorolni. 

\subsubsection{Legjobb összevonáson alapuló szegmentálás}
A legjobb összevonáson alapuló szegmentálás (\textit{Best merge based segmentation})
- mint a neve is utal rá - egy összevonás alapú, iteratív szegmentálási módszer
\cite{bestMerge,bestMerge2}. Az algoritmus kezdõállapotában minden pixelértéket 
külön szegmensnek tekint, és minden iterációs lépésében egy megadott 
\textit{homogenitási kritérium} szerint egymáshoz legközelebb álló szomszédos szegmenseket
vonja össze. A mûvelet addig fut, amíg el nem ér egy megadott szegmens-számot,
vagy a homogenitási kritérium alapján már nem tudna több szegmenst összevonni.

A homogenitási kritériumok általában olyan \textit{távolságfüggvény}eken alapulnak,
amelyek a szegmensek által tartalmazott intenzitásértékeket használják fel. Ilyen távolságfüggvények
például a \textit{divergencia}, a \textit{Bhattacharyya távolság}\cite{bhattacharyya}, vagy az
\textit{euklideszi távolság}).

A szegmentáló algoritmus reprezentálható egy olyan gráfalapú megközelítéssel, ahol az egyes 
pixelek rácsgráfjából indulunk ki és a távolságfüggvények alapján \textit{csúcsokat} vonunk 
össze. Az egyes csúcsok közötti távolságok \textit{élek} formájában jelennek meg a gráfban.
Ezzel a megközelítéssel és modern adatstruktúrák felhasználásával az algoritmus teljesítménye
nagymértékben növelhetõ.

\subsection{Regionális mûveletek MapReduce alapú feldolgozása}
Mivel a régiók kiterjedése nagyban függ az adott mûvelettõl 
és paraméterezésétõl, valamint a pixelek intenzitásától,
így az input particionálása a MapReduce feldolgozáshoz meglehetõsen komplex feladat.
Az egyes partíciókhoz úgy kell megválasztani az átfedõ területeket, hogy általánosságban
mindegyik régió kialakításához elegendõ adatra legyen szükség.

\subsubsection{Szegmentáló mûveletek futtatása}
A szegmentálás során az alapmûveletek legtöbbször módosítás nélkül alkalmazhatók
Map-, illetve Reduce függvényekként, azonban a feldolgozási folyamatot szükséges 
kiegészíteni egy utófeldolgozó lépéssel: azok a feldolgozó egységek, amelyek egymással
szomszédos, átfedõ partíciókat dolgoznak fel, az átfedett területen duplikált szegmenseket 
hozhatnak létre. A megfelelõ eredmény érdekében ezeket a szegmenseket eliminálni kell a 
végsõ szegmenshalmazból. Erre az alábbi heurisztikák használhatóak\cite{aegisHadoop}:

\begin{itemize}
	\item Ugyanazzal a pixelhalmazzal rendelkezõ szegmensek esetén az egyiket kitöröljük
	\item Ha egy szegmens egy másik szegmens részhalmaza, akkor két lehetõségünk van:
	Ha a kisebbik szegmens az átfedés határán helyezkedik el (tehát az egyik része a partícióban
	foglal helyet, a másik része pedig az átfedésben), akkor kitöröljük.
	Ha a szegmens az átfedésen belül helyezkedik el, akkor 	megtartjuk, és a tartalmazó
	szegmensbõl kitöröljük a pixelértékeit.
	\item Ha két szegmens közös pixeleket tartalmaz, akkor a ezek a pixelek mindkét 
	szegmensbõl törlésre kerülnek és egy új szegmenst hozunk létre belõlük.
\end{itemize}

A szegmentáló mûveletek ilyen módon történõ feldolgozása komplex feladat. Egyrészt
ugyan magukat az algoritmusokat nem szükséges módosítani, de a feldolgozást ki kell terjeszteni
egy plusz lépéssel, amely növeli a komplexitást. Másrészt az egyes partíciókat jelentõs
méretû átfedéssel kell létrehozni, amely növeli a tárterületet. Azonban még ekkor is fennáll
a lehetõség, hogy a mûveletnek további adatokra van szüksége - 
helytelen paraméterezés vagy homogén kép esetén akár az input kép egészére is. 

\subsection{Regionális mûveletek feldolgozása Orleans platformon}
Az Orleans rendszer a MapReduce rendszertõl eltérõ megközelítést alkalmaz az elosztott feldolgozásra,
amellyel - elméletben - kiküszöbölhetõek az elõzõ szakasz végén említett nehézségek.
A feldolgozás során itt is az aktorok egymás közti kommunikációját használjuk ki.

\subsubsection{Vágást alkalmazó szegmentáló mûveletek futtatása}
A vágást alkalmazó szegmentáló mûveletek kezdetben az input kép egészét egy darab szegmensnek tekintik, és egy
meghatározott vágási kritérium alapján több több szegmensre osztják fel - például a korábban ismertetett
negyedelõ fa alapú szegmentálás esetén négy egyforma méretû részre. A vágást alkalmazó mûveletek ennek
megfelelõen könnyedén felkészíthetõek az elosztott feldolgozásra. Tekinthetjük a particionálás mûveletét
egy kiinduló vágó lépésnek, mivel megfelelõen inhomogén képek és megfelelõ paraméterezés esetén
a mûvelet elsõ lépése nagy valószínûséggel egy vágás lenne. A particionálásnál így egyedül arra
kell figyelni, hogy ugyanolyan méretû és formájú partíciókat hozzunk létre kezdetben, mint amilyeneket a
vágások során hozna létre a szegmentáló algoritmus.

\subsubsection{Összekapcsolást alkalmazó szegmentáló mûveletek futtatása}
Ahhoz, hogy a MapReduce esetben bevezetett utófeldolgozó lépést eliminálhassuk a feldolgozásból,
tudjuk, szükséges hogy a szegmentáló mûvelet által létrehozott szegmensek minden lépésben 
konzisztensek legyenek, tehát a mûvelet minden iterációjában ugyanazok a szegmensek jelenjenek meg,
mint ha a mûveletet a kép egészére, particionálás nélkül futtatnánk. Az AEGIS rendszerben
a szegmentáló mûveletek egy \textit{szegmensgyûjtemény}t (\textit{SegmentCollection}) használnak 
a szegmensek nyilvántartására. A szegmensgyûjtemény osztály tulajdonképpen egy \textit{sok-egy} megfeleltetés
a feldolgozandó kép pixelei és az egyes szegmensek között. Minden pixelre lekérdezhetjük az õt tartalmazó
szegmenst (ha van ilyen), illetve minden szegmenshez eltároljuk, mely pixeleket tartalmaz.
Elosztott feldolgozás során minden feldolgozó egység saját szegmensgyûjteménnyel rendelkezik, a pixelek
koordinátái pedig az adott feldolgozandó input relatív koordináta-rendszerében helyezkednek el. 
Ha az egységeknek biztosítani tudnánk egy olyan szegmensgyûjteményt, amely - elméletben - feldolgozandó
teljes input képre tartalmazná az összes szegmenst, akkor a szegmentálás állapota minden
idõpillanatban ugyanazt a konzisztens állapotot tükrözné vissza, mint ha egy gépen történne a feldolgozás.

Az ötletet a korábban bemutatott virtuális raszter adta: Vezessünk be egy virtuális raszteren
operáló, \textit{virtuális szegmensgyûjtemény}t (\textit{VirtualSegmentCollection}), 
mely az eredeti kép dimenzióival rendelkezik, és az összes feldolgozó egységet összekapcsolja egy
\textit{szegmens szerviz}-en (\textit{SegmentService}) keresztül. Az egyes feldolgozó egységek lokálisan
nem tárolják el az input kép egészére a szegmensinformációt, 
csupán a saját területüket valamilyen módon érintõ szegmenseket.

A szegmentáló mûveletek ezen virtuális szegmenseken operálnak a saját partíciójuk által meghatározott
munkaterületen. A virtuális raszteren és a virtuális szegmensgyûjteményen keresztül 
lényegében a teljes input kép bármelyik pixelét és szegmensét elérhetik. Ezzel az algoritmusok
bármilyen módosítás nélkül, tetszõleges számú partíción, elosztottan futtathatók.

A szegmens szerviznek alapvetõen két funkciója van: Egyrészt biztosítja a szegmensek elérését. Ehhez
a lokális partícióhoz tartozó szegmenseket a kiinduló szegmensgyûjteményhez hasonlóan tartja
nyilván, más partíciók által tartalmazott szegmenseket pedig a távoli partíciót feldolgozó egységnek
intézett üzenetküldéssel kéri el. 
Másrészt, ha a feldolgozás során szükséges egy távoli szegmens módosítása 
(például szegmensek összekapcsolása vagy vágása), a szegmens szerviz
értesíti a távoli szegmenst tartalmazó szervizt a módosításról. 

\begin{figure}[H] 
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=155mm]{figures/segmentUpdate.png}
	\caption{Egy lokális szegmens távoli szegmenssel történõ összekapcsolása \label{fig:segmentUpdate}}
\end{figure}

A \ref{fig:segmentUpdate}. ábrán egy olyan eset látható, amikor egy lokális szegmenst
egy távoli szegmenssel kapcsolunk össze. A Szegmens szerviz (\textit{Segment Service}) ekkor távoli szegmenst 
tartalmazó Grain-hez intézett üzenetküldéssel (\textit{Get Remote Segment}) kéri el
a szükséges szegmenst, a lokális szegmenst pedig a lokálisan nyilvántartott
szegmensek gyûjteményétõl kérdezi le (\textit{Segment Collection}). A távoli Grain is
a saját szegmensgyûjteményébõl továbbítja a kívánt szegmenst. A két szegmens
összekapcsolása után egyrészt a Grain a saját szegmensgyûjteményét is frissíti, valamint a
távoli Grain-nek is elküldi az összefésült szegmenst (\textit{Update Remote Segment}), 
így ez a Grain is frissítheti a gyûjteményét.

Mivel a szerviz közvetlenül nem
összekapcsolható más szervizekkel, csupán a feldolgozó Grain-ekkel, így ezek interfésze
kiegészítésre került a megfelelõ lekérdezõ (\textit{GetRemoteSegment}) és módosító (\textit{UpdateRemoteSegment}) mûveletekkel, tehát lényegében \textit{proxy}
objektumokként szolgálnak a szegmens szervizek kommunikációjában.

Fontos megjegyezni, hogy a fent bevezetett virtuális szegmens használata esetén is létrejöhetnek olyan
szegmensek a rendszerben, melyeket több feldolgozó egység is tartalmaz. Ha egy lokális szegmens 
összekapcsolásra kerül egy távoli szegmenssel, akkor az összekapcsolt szegmenst mindkét feldolgozó
egység tartalmazni fogja, mivel nem egyértelmûen eldönthetõ, hogy melyik partícióhoz tartozik.
Azonban a szerviz alkalmazásával a duplikált szegmensek pontosan meg fognak egyezni
a tartalmazott pixelek függvényében, így nem szükséges olyan elimináló logika végrehajtása, mint a
MapReduce esetén, elegendõ az egyik szegmenst kitörölni a végsõ gyûjteménybõl.

%TODO Add figure.

\section{Globális mûveletek}
A globális mûveletek feldolgozásuk során az eredményt az input kép valamilyen globális tulajdonsága alapján
(például hisztogram) képesek kiszámítani. A particionálás - ha egyáltalán lehetséges - meglehetõsen
komplex feladat. A globális mûveletek azonban kulcsfontosságú részét képezik a távérzékelt adatokból
történõ tematikus információkinyerésnek. Mind a pont alapú osztályozó mûveletek (pl.: küszöbölés), mind
pedig a regionális, a szegmentáláson és klaszterezésen alapuló tematikus osztályozás alapvetõ részei.
A fenti tényezõk miatt az Orleans rendszer gyakorlati alkalmazhatósága nagyban függ a globális mûveletek
területén nyújtott teljesítményétõl.

\subsection{Hisztogram alapú küszöbölés}
A tematikus osztályozás legegyszerûbb algoritmusa, a \textit{konstans küszöbölés} a lokális mûveleteknél
került bemutatásra. Ezen mûvelet legnagyobb hátránya, hogy a küszöbértéket manuálisan kell beállítani
minden egyes mûveletre, és az optimális érték minden inputra különbözhet.

A \textit{hisztogram alapú} küszöbölõ algoritmusok az input képre kiszámított hisztogram alapján
próbálnak optimális küszöbértéket keresni. A legtöbb mûvelet úgy próbálja a küszöbértéket meghatározni, 
hogy a tõle kisebb, illetve nagyobb intenzitásértékek átlaga között a legnagyobb legyen a különbség.

Az algoritmusokat legtöbbször szürkeárnyalatos képek küszöbölésére használjuk, azonban távérzékelt
felvételek bármelyik spektrális sávjának küszöbölésére is alkalmazható.

\subsubsection{Kiegyensúlyozott hisztogram küszöbölés}
A \textit{kiegyensúlyozott hisztogram alapú küszöbölés}\cite{balancedHistogramThresholding} két különbözõ
osztályt képes megkülönböztetni a képen: egy elõteret és egy hátteret. Az algoritmus
\textit{súlyozza} az input hisztogramot, és azt a pontot keresi meg futása során, ahol a hisztogram érték
"egyensúlyban" van. Ez azt jelenti, hogy a ponttól azonos mennyiségû alacsonyabb-, illetve magasabb
intenzitású pontokat tartalmaz a hisztogram. 
A kiinduló egyensúlypont a hisztogram közepe, és a mûvelet minden lépésében a "nehezebb" 
oldalból vesz el \textit{hisztogram osztályokat} mindaddig, amíg ki nem egyensúlyozza a hisztogramot.

Az algoritmus egyszerûsége miatt széles körben használt, túlzottan zajos képek esetén azonban nem 
ad biztosan eredményt. Ez kiküszöbölhetõ, ha a hisztogram "kiugró" értékeit nem vesszük 
figyelembe\cite{bhtOptimal}.

\subsubsection{Otsu küszöbölés}
A \textit{Nobuyuki Otsu} után elnevezett \textit{Otsu küszöbölés}\cite{otsu} egy bináris küszöbölõ
algoritmus. A mûvelet a kiegyensúlyozott hisztogram küszöböléshez hasonlóan feltételezi, hogy az input
kép két osztályból (egy elõtérbõl és egy háttérbõl) tartalmaz pixelértékeket, és azt a küszöbértéket
keresi, ahol maximális a két osztály különbsége. 

Az algoritmus következõ: Az input sáv $L$ különbözõ intenzitást tartalmaz, a normalizált hisztogram
pedig minden $i$ intenzitáshoz megadja annak $P_i$ elõfordulási gyakoriságát. Azt a $T$ küszöbértéket
keressük, amely az elõtér/háttér közötti \textit{varianciá}t maximalizálja.

A háttér ($q_b$) illetve az elõtér ($q_o$) pixeleinek gyakorisága (valószínûsége):
\begin{align}
q_b(T) = \sum_{i=1}^{T}p_i && q_o(T) = \sum_{i=T+1}^{L}p_i && \text{és} && q_b(T) + q_o(T) = 1
\nonumber
\end{align}

A $T$ küszöbérték két részre osztja a normalizált hisztogramot ezek átlaga ($\mu_b,\space\mu_o$)
és varianciája ($\sigma^2_b,\space\sigma^2_o$) az alábbi:

\begin{align}
\mu_b = \frac{1}{q_b(T)}\sum_{i=0}^{T}i*P(i) && \mu_o = \frac{1}{q_o(T)}\sum_{i=T+1}^{L}i*P(i)
\nonumber
\end{align}
\begin{align}
\sigma^2_b = \frac{1}{q_b(T)}\sum_{i=0}^{T}(i - \mu_b)^2*P(i) && 
\sigma^2_o = \frac{1}{q_o(T)}\sum_{i=T+1}^{L}(i - \mu_o)^2*P(i)
\nonumber
\end{align}

A fentiek, valamint az input kép szórásnégyzete $(\sigma^2)$ 
felhasználásával kaphatjuk a hisztogram osztályon belüli $(\sigma_w^2)$ 
és az osztályok közötti $(\sigma_k^2)$ szórásnégyzeteket:

\begin{center}
	$\sigma_w^2(T) = q_b(T)*\sigma_b^2(T) + q_o(T)*\sigma_o^2(T)$
\end{center}
\begin{center}
	$\sigma_k^2(T) = \sigma_w^2(T)$
\end{center}

A fenti $\sigma_w^2(T)$ és $\sigma_k^2(T)$ szórásnégyzetek összege minden $T$ küszöb
esetén konstans, így az optimális küszöbérték az az érték, amelyre $\sigma_w^2(T)$ maximális
(tehát az osztályon belüli szórás minimális), vagy $\sigma_k^2(T)$ maximális (vagyis 
az egyes osztályok közötti szórás maximális).

\subsection{Klaszterezés}
A \textit{klaszterezés} a tematikus osztályozás egyik kulcsfontosságú lépése. 
A szegmentáló algoritmusok ugyan megfelelõen csoportosítják a homogén pixeleket,
azonban a létrejövõ szegmensek nem feleltethetõek meg egyértelmûen a keresett
tematikus osztályoknak. Legtöbbször egy tematikus osztályt több, spektrálisan hasonló 
szegmens épít fel (pl.: egy távérzékelt felvételen több különbözõ vízzel borított terület
is megjelenhet, melyek nem feltétlenül szomszédosak egymással). A klaszterezõ mûveletek
feladata, hogy a \textit{spektrálisan} összefüggõ szegmenseket csoportosítsa, és a létrejövõ
csoportokat megfeleltesse az egyes tematikus osztályoknak. A klaszterezõ algoritmusok 
az egyes szegmensek geometriai helyzete helyett azok \textit{spektrális intenzitástér}ben 
való elhelyezkedése alapján keresik az egyes csoportokat, így a csoportok 
kialakítása során már mindegy, hogy az egy tematikus kategóriába tartozó szegmensek
hol helyezkednek el az input képen.

\subsubsection{ISODATA algoritmus}
Az \textit{ISODATA algoritmus (Iterative Self-Organizing Data Analysis Technique)}\cite{isodata}
egy euklideszi távolságon alapuló klaszterezõ algoritmus, mely több 
iteráción keresztül határozza meg az optimális osztályokat. 
 Az algoritmus a következõ lépésekbõl áll:

\begin{enumerate}
	\item Válasszunk meghatározott mennyiségû kiinduló klaszterközéppontot az intenzitástérben.
	\item Minden szegmenshez (vagy pixelhez) rendeljük hozzá annak a klaszternek a sorszámát,
			amelynek középpontja az intenzitástérben a legközelebbi az euklideszi távolság
			alapján.
	\item Határozzuk meg minden klaszterre azoknak a képpontoknak az átlagát, amelyek 
			az aktuális iterációban az adott klaszterhez sorolódtak. Ez fogja meghatározni
			az új klaszterközéppontokat.
	\item Ha a leállási feltétel nem teljesül, folytassuk 2.-tõl.
\end{enumerate}

Az algoritmus leállási feltétele, hogy a létrejött osztályok átlaga az osztályok lehetséges
középpontjába helyezõdik, tehát az egyes iterációk eredményei között nagyon alacsony a 
különbség. 

Az algoritmus nagy elõnye, hogy nem szükséges kezdeti információval rendelkeznünk az adatok
spektrális tulajdonságairól, így nincs jelentõsége hogy hol helyezkednek el a kezdõ
klaszterközéppontok, ha elég sok iteráció engedélyezett.

\subsection{Globális mûveletek MapReduce alapú feldolgozása}
Globális mûveletek esetén általában a feldolgozandó adat a megfelelõ globális információ
birtokában késõbb elosztottan futtatható, azonban ezen globális információ kiszámítása
mindenképpen központilag kell, hogy történjen. Az is lehetséges, hogy az adatok 
valamilyen egyéb szempont alapján történõ \textit{újraparticionálás}a után végezhetõ
el az elosztott feldolgozás.

\subsubsection{Hisztogram alapú küszöbölõ algoritmusok}
A hisztogram alapú algoritmusok indulásának pillanatában szükséges a teljes kép hisztogramának
rendelkezésre állása. Ez egy elõfeldolgozó \textit{Map} illetve \textit{Reduce} 
mûveletekkel könnyedén elõállítható a \ref{subs:aegisHadoop}. szakaszban a
\textit{hisztogram-kiegyenlítés} mûveleténél ismertetett módszerrel: Elsõ lépésként egy Map függvénnyel
kiszámítjuk minden darabra a hisztogramot, majd egy Reduce mûvelet segítségével ebbõl elõállítjuk
a teljes kép hisztogramát. Ezután az egész input kép hisztogramának ismeretében egy
harmadik Map függvény végrehajtja a kívánt küszöbölõ mûveletet.

\subsubsection{Klaszterezõ algoritmusok}
A klaszterezõ algoritmusok - mint korábban említésre került - az input pixelek, vagy szegmensek
intenzitásértékeibõl elõállított intenzitástéren operálnak. Ez az intenzitástér az input kép
geometriai particionálásához hasonló módszerrel particionálható és elosztottan feldolgozható.
A tematikus osztályozás folyamata során a klaszterezõ mûveletek legtöbbször egy szegmentáló 
mûvelet eredményhalmazát (szegmensek egy csoportját) kapják meg. MapReduce feldolgozás esetén
ezeket az eredményhalmazokat összegyûjthetjük a szegmentálás végezte után egy Reduce lépésben
(A szegmentálás során az elõzõ szakaszban említett duplikált szegmensek eliminálásához 
egyébként is szükséges egy központi Reduce lépés), majd a spektrális intenzitástér alapján
újraparticionálhatjuk õket. Ezután az egyes partíciókat újabb \textit{Mapper} függvényekkel,
elosztottan feldolgozhatjuk. Mivel a végsõ szegmensgyûjtemény számossága jellemzõen 
nagyságrendekkel alacsonyabb, mint az input pixelek darabszáma, így az adatok újraelosztása 
a feldolgozó Mapper függvények között nem okoz jelentõs teljesítménycsökkenést. 

Fontos megjegyezni, hogy a spektrális intenzitástér alapján újraparticionált adatokon 
elosztottan futtatott klaszterezés tulajdonképpen egy regionális mûvelet lesz. Emiatt 
szükséges ezen particionálás
során is átfedéseket definiálni, és a klaszterezés során azokat a szegmenseket, amelyek
több klaszterbe is besorolásra kerültek, eliminálni a végsõ eredményhalmazból. 
Ezt az eliminálást egy újabb Reduce mûvelet végezheti el a klaszterezés végeztével.

\subsection{Globális mûveletek Orleans alapú feldolgozása} \label{subs:globalProcessing}
A globális mûveletek elméletben az Orleans platformon is hasonló módon kerülnek végrehajtásra,
mint a MapReduce esetben, csupán az alkalmazott ötletek tekintetében volt különbség. 
A hisztogram alapú algoritmusok esetén például a központi hisztogram-kiszámító lépést nem
az Orleans rendszer végzi, hanem a hisztogramot elõzetesen a particionálás során 
kiszámítjuk, és a \ref{sec:partitioning}. szakaszban ismertetett partíció leíró fájlba
helyezzük. Mivel ezt a partíció leíró fájlt az összes feldolgozó Grain megkapja, így
a hisztogram alapú küszöbölõ algoritmusok indításának pillanatában minden feldolgozó
egység számára rendelkezésre áll.

\subsubsection{Klaszterezõ algoritmusok}
A klaszterezõ eljárások elosztott futtatásának alapötlete megegyezik a MapReduce
esetben ismertetett megoldással - a szegmentálás eredményét összegyûjtjük az egyes
Grain-ektõl, a szegmenseket elhelyezzük a multispektrális térben, majd particionáljuk,
és újabb feldolgozó Grain-ek segítségével elosztottan elvégezzük a klaszterezést. 
A különbség abban nyilvánul meg, hogy a particionálás során nem definiálunk
átfedéseket, hanem a szükséges távoli értékeket az egyes feldolgozó egységek
a regionális mûveletekhez hasonlóan távoli üzenetküldés segítségével "kérik el"
egymástól.

% ------------------------------------------------------------------------------

\chapter{Eredmények} \label{ch:results}
A diplomamunka fõ célja annak kutatása volt, hogy a vizsgált Orleans keretrendszer megfelelõ
alapot tud-e nyújtani a távérzékelt felvételek feldolgozásának területén.
A rendszer gyakorlati használhatóságát akkor tudjuk igazán megismerni, ha a napjainkban 
legtöbbször felhasznált mûholdak által szolgáltatott adatok feldolgozására vizsgáljuk a 
teljesítményét. A tesztelés során így esett a választás napjaink két meghatározó
mûholdcsaládjára, a \textit{Landsat}, és a 
\textit{SPOT (Satellite Pour l'Observation de la Terre, "Mûhold a Föld megfigyelésére")}
mûholdak által szolgáltatott adatokra. 
A mûholdak által szolgáltatott adatok \textit{GeoTIFF}
formában álltak rendelkezésre, 
a fájlok beolvasása és az eredmény kiírása pedig az AEGIS keretrendszerben 
implementált GeoTIFF olvasó-, illetve író mûveletek felhasználásával valósult meg.
Az AEGIS keretrendszer segítségével végeztük el továbbá ezen adatok felosztását is.

Ahhoz hogy minél részletesebb képet kapjunk a rendszer teljesítményérõl, 
a mûveleteket két különbözõ környezetben futtattuk több, eltérõ méretû
adatra. Az elosztott környezetet tíz darab átlagos számítási-, illetve
I/O teljesítménnyel
rendelkezõ számítógép összekapcsolt rendszere adta. Ezen a klaszteren
egyrészt az Orleans segítségével futtattunk teljesítményteszteket,
valamint ezen adatok MapReduce architektúrával való összehasonlításának érdekében
ugyanezen a klaszteren a Hadoop keretrendszer felhasználásával is megmértük
az egyes mûveletek teljesítményét. 
Mindamellett, hogy a két elosztott rendszer közötti teljesítményt
összehasonlítjuk, szeretnénk arról is információt kapni, hogyan viszonyul az
elosztott feldolgozás hatékonysága az egy számítási egységen végzett 
végrehajtáshoz. Ennek megfelelõen egy, napjainkban erõsnek mondható
számítási-, és I/O kapacitással rendelkezõ \textit{PC} szolgált a 
\textit{lokális} feldolgozás
tesztelésére. Az eredmények közlése a mûveletek bemutatásához hasonlóan
munkaterület-csoportonként történik.

\section{Lokális mûveletek}  %TODO Consider writing Lokáis mûveletek eredményei	
Mivel a választott lokális algoritmusok az eredménykép minden %TODO Recompose
pixelét konstans idõben kiszámítják, ezért a 
végrehajtásuk során mért teljesítményt fõleg 
az input beolvasása, az eredmény kiírása, 
valamint a rendszer folyamatainak kezdeti felállítása befolyásolja. 
Ebben az esetben azok a rendszerek nyújtanak megfelelõ teljesítményt,
melyeknek inicializálási költsége minél alacsonyabb, és amelyeknek 
a számítógép háttértárával történõ kommunikációja a leggyorsabb. 

Ezeket a feltevéseket a mért eredmények is alátámasztották: a legegyszerûbb,
invertálás mûvelet egy Landsat felvételen történõ végrehajtása során
csak négy partíció elosztott feldolgozásával tudta az Orleans
rendszer megközelíteni a lokális feldolgozást, a Hadoop pedig még 
nyolc partíció felhasználásával sem tudta elérni a lokális környezeten
mért teljesítményt. 

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=130mm]{figures/diagrams/inversion.png}
	\caption{Invertálás mûvelet végrehajtása nagyméretû felvételekre}\label{fig:inversion}
\end{figure}

Ha azonban az elosztott rendszerek egymáshoz képesti teljesítményét vizsgáljuk, 
láthatjuk, hogy az Orleans keretrendszer jobb eredményeket produkál mint a Hadoop,
mivel inicializálási költsége jelentõsen alacsonyabb. 
Az egyes Grain-ek könnyen példányosíthatóak és csak annyi 
feldolgozó Grain-t hozunk létre, amennyi feldolgozandó fájldarabbal összesen
rendelkezünk, ezért az indítás nem okoz jelentõs plusz költséget. 
A Hadoophoz képest további elõny, hogy az Orleans 
rendszer meglehetõsen "könnyûsúlyú", a számításokat végzõ aktorok menedzselésén
kívül nem rendelkezik olyan kiterjedt eszközkészlettel (például az egyes
folyamatok, vagy a felhasznált erõforrások monitorozására alkalmas eszközök),
mint a Hadoop rendszer. Jóllehet ezek az eszközök nagy segítséget nyújtanak 
az elosztott feldolgozás egyéb területein, a távérzékelt felvételek
feldolgozása esetén felesleges pluszt jelentettek a rendszer felállításában, 
és a rendelkezésre álló erõforrásokban is. A Hadoop rendszer esetén
például több mûvelet végrehajtása során is elfogyott a rendelkezésre 
álló memória, mivel csupán a rendszer futtatásához jelentõs mennyiségû 
memóriára volt szükség, és a fennmaradó erõforrás nem volt elég a mûvelet
végrehajtásához.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=130mm]{figures/diagrams/toaref.png}
	\caption{A ToA-Reflektancia mûvelet végrehajtása nagyméretû felvételekre}\label{fig:toaref}
\end{figure}

A rendelkezésre álló erõforrások a lokális végrehajtás során is problémákat
okozhatnak. Mivel a Landsat és a SPOT mûholdak által szolgáltatott felvételek
mindegyike 8 bites radiometriai felbontással rendelkezik, a ToA-Reflektancia
mûvelete pedig 32 bites felbontást eredményez minden sávra, ezért az eredménykép
négyszer nagyobb lesz, mint az input adat. A mûvelet eredményét lokálisan például
egy darab output fájlba nem tudjuk kiírni, mivel az AEGIS architektúra 
jelenleg nem támogatja ekkora fájlok írását.

A lokális mûveletek területén összegzésképp tehát elmondható, hogy az adatok
feldolgozásában jelentõs szerepet játszik az input beolvasása és az eredmény 
kiírása, ezért az elosztott rendszerek csak akkor tudják felvenni a versenyt
a lokális feldolgozó egységgel, ha megfelelõ teljesítményû háttértár áll a
rendelkezésre. Mindezek mellett pedig fontos szempont, hogy az elosztott
rendszer elindításának milyen plusz költsége van, mivel egyszerû mûveletek
esetén az inicializálás gyakran több idõt vehet igénybe mint az egész mûvelet
végrehajtása.

\section{Fokális mûveletek}
Fokális mûveletek esetén a fõ kérdés az, tud-e az aktorok közti kommunikáción alapuló, 
átfedésmentes implementáció közel hasonló, vagy jobb teljesítményt nyújtani, mint 
az átfedéseken alapuló megoldás.

A tesztelt fokális munkaterületû algoritmusok mûveletigénye nagyobb, mint a 
lokális mûveleteké. A vizsgált szûrések egy $V = N \times N$ input képre és 
egy választott $K=M\times{}M$ kernelmátrixra $O(N^2K^2)$ idõben tudják
elõállítani az eredményt. Emiatt ezen mûveletek futtatása esetén az I/O 
kapacitás helyett inkább a feldolgozó egységek számítási kapacitása
lesz a meghatározó, ha az egyes partíciókra definiáltunk átfedéseket. 

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=130mm]{figures/diagrams/gaussianBlur.png}
	\caption{Gauss szûrõ végrehajtása közepes méretû felvételekre}\label{fig:gaussianBlur}
\end{figure}

A \ref{fig:gaussianBlur}.
ábrán látható, hogy a közepes számítási teljesítménnyel rendelkezõ
elosztott feldolgozó egységek megfelelõ számú partíció esetén felülmúlják a nagy teljesítményû lokális feldolgozó környezetet.
A Hadoop esetén a fokális mûveletek feldolgozásánál kevésbé jelentõs
a rendszer inicializálásának magas költsége, sõt, az eredményekben megfigyelhetõ, hogy
a Hadoop jobban képes kihasználni a rendelkezésre álló erõforrásokat, mint
az Orleans rendszer.  

\subsubsection{Átfedések használata nélküli feldolgozás}
A platform és az aktor alapú feldolgozási módszer használhatóságát alapvetõen
az átfedések nélküli felvételek feldolgozásánál nyújtott teljesítménye 
határozza meg. Ha csupán az aktorok kommunikációján alapuló feldolgozási
módszerrel közel azonos, vagy jobb teljesítményt tudunk elérni, mint az átfedések
használatával, akkor nagy valószínûséggel a regionális és a globális mûveletekre
is hatékonyan tudjuk ezt a megközelítést alkalmazni, és ebben az esetben a platform
segítségével a tematikus osztályozás minden lépését elvégezhetnénk.

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=130mm]{figures/diagrams/gaborFilter.png}
	\caption{Gabor szûrõ alkalmazása közepes méretû képekre Orleans platformon}\label{fig:gaborFilter}
\end{figure}

A mért eredmények azonban nem ezt bizonyították. A fenti, \ref{fig:gaborFilter}.
ábrán egy Gabor szûrõ alkalmazásának futási ideje látható különbözõ mennyiségû 
partíció esetén. A diagramról egyértelmûen leolvasható, hogy az átfedések nélküli
esetben a futási idõ a partíciók számának növelésével
jelentõs mértékben növekszik, és egyre inkább eltávolodik
az átfedéses feldolgozás során mért teljesítménytõl. 

Átfedés nélküli esetben
a teljesítmény annak függvényében változhat, mennyi adatra van szükségük 
az egyes feldolgozó egységeknek más Grain-ektõl. Ha kevés alkalommal történik 
távoli pixel-elérés, akkor jellemzõen a futási idõ is csökken. 

Egy fejlesztési lehetõség lett volna például az egyes Grain-ek közötti 
\textit{gyorsítótárazás (caching)} bevezetése, melynek során távoli pixel-elérés esetén
nem csupán egy adott pixelt kérnének el az egyes Grain-ek egymástól, hanem
a pixel egy meghatározott sugarú környezetét is. Ezeket
a pixeleket ezután lokálisan eltárolhatnák, és abban az esetben, 
ha a végrehajtandó algoritmus futása során szükség lenne ezen pixelértékek 
valamelyikére, azok már lokálisan rendelkezésre állnának. Egy ilyen gyorsítótár 
implementálása azonban egyrészt túlmutatott a diplomamunka keretein, másrészt pedig
a mért eredmények arra engedtek következtetni, hogy valószínûleg ezen javítás
bevezetése esetén sem tudnánk megközelíteni azt a teljesítményt, ha az adatok
lokálisan rendelkezésre állnak minden feldolgozó egység számára.

\section {Regionális mûveletek}

\subsubsection{Virtuális szegmensgyûjtemény használata}

\newpage

\section{Globális mûveletek}

\subsubsection{Hisztogram alapú küszöbölés}
Az ismertetett hisztogram alapú küszöbölõ algoritmusok abból a feltevésbõl indulnak ki, hogy 
a mûvelet indításakor rendelkezésre áll a teljes input képre vonatkozó hisztogram.
Ehhez a particionálás során kiszámított hisztogramot a partíció leíró fájlba helyezzük, 
melyet minden egyes feldolgozó egység meg fog kapni az inicializálás során. Ezzel
eliminálunk minden kommunikációt a feldolgozó Grain-ek között, így ezen mûveletek 
lényegében lokális munkaterületû mûveletek lesznek.

Mind a kiegyensúlyozott hisztogram küszöbölés, mind az Otsu küszöbölés közel azonos
eredményeket mutattak a lokális-, és az Orleans alapú feldolgozás során, ezért
csak az egyik mûvelet futtatásának eredménye kerül elemzésre:

\begin{figure}[h!]
	\centering
	\captionsetup{width=0.8\textwidth, justification=centering}
	\includegraphics[width=130mm]{figures/diagrams/otsuThresholding.png}
	\caption{Otsu küszöbölés alkalmazása nagyméretû képekre Orleans platformon}\label{fig:otsuThresholding}
\end{figure}

A fenti, Otsu küszöbölés eredményén látható, hogy lokális esetben a mûvelet a kezdeti
hisztogram-kiszámítás miatt magasabb mûveletigénnyel rendelkezik, így az Orleans
rendszer már két partíció használata esetén is megközelíti a lokális eredményt, 
több partíció felhasználásával pedig már jelentõsen gyorsabb.

\subsubsection{Klaszterezés}
A korábbi, fokális és regionális eredményeket ismertetõ szakaszokban láthattuk,
hogy az aktorok azonnali, aszinkron üzenetküldésén alapuló kommunikáció
egyik mûveletnél sem tudta felvenni a versenyt a partíciók átfedéssel
történõ feldolgozásával. Az egyes feldolgozó egységek közötti hálózati kommunikáció
túl nagy plusz költséget jelent a feldolgozás teljesítményében.

Mivel a \ref{subs:globalProcessing} fejezetben a klaszterezõ algoritmusok
feldolgozására egy olyan ötlet került bemutatásra, melyben a végrehajtás
minden fázisában az aktorok kommunikációját használjuk ki, így ez az ötlet
a diplomamunka során az Orleans architektúrán nem került implementálásra.
A kezdeti, prototípus implementációk nem produkáltak 
olyan teljesítményt, amely akár csak megközelítené a lokális, vagy a Hadoop
környezetben mért eredményeket. Ennek alapján kijelenthetõ, hogy az Orleans 
platform aktor implementációja nem ideális a klaszterezõ algoritmusok elosztott
végrehajtására.


% ------------------------------------------------------------------------------

\chapter{Összefoglalás} \label{ch:summary}

Gyorsítótárazás, de a szegmentálás esetén nem nyújtana megfelelõ teljesítményt

Mivel a klaszterezõ algoritmusok a tematikus osztályozás folyamatának elengedhetetlen
részei, és mivel a fent 

%\section{Továbbfejlesztési lehetõségek?}

% ------------------------------------------------------------------------------


\cleardoublepage

\phantomsection
\addcontentsline{toc}{chapter}{Irodalomjegyzék}

\begin{thebibliography}{9}
\bibitem{richards} Richards, J. A., Jia, X. \textit{Remote Sensing Digital Image Analysis, An Introduction, fifth edition}, Springer, 2013, 978-3-642-30061-5.

\bibitem{remoteSensingLecture} László, I., Csornai, G., Fekete, I., Giachetta, R. \textit{Távérzékelt felvételek elemzése}, Egyetemi jegyzet, Eötvös Loránd Tudományegyetem Informatikai Kar, Budapest, 2014.

\bibitem{aegis} Giachetta, R. \textit{AEGIS - A state-of-the art component based spatio- temporal framework}, OSGeo Journal 13.1, pp. 68-77, 2014.

\bibitem{aegisHadoop} Giachetta, R., Fekete, I. \textit{A case study of advancing remote sensing image analysis}, Acta Cybernetica, 22, pp. 57-79, 2015.

\bibitem{shapefile} ESRI, ESRI. \textit{Shapefile technical description.} An ESRI White Paper (1998).

\bibitem{geotiff} Ritter, N., and M. Ruth. \textit{The GeoTiff data interchange standard for raster geographic images}. International Journal of Remote Sensing 18.7 (1997): 1637-1647.

\bibitem{dotnetOrleans} \textit{Microsoft Orleans, A straightforward approach to building distributed, high-scale applications in .NET}, http://dotnet.github.io/orleans

\bibitem{orleansMSR} Philip A. Bernstein, Sergey Bykov, Alan Geller, Gabriel Kliot, Jorgen Thelin: \textit{Orleans: Distributed Virtual Actors for Programmability and Scalability}, Microsoft Research

\bibitem{mapAlgebra} \textit{Map Algebra: Global, Zonal, Focal and Local Operations}, http://gisgeography.com/map-algebra-global-zonal-focal-local/

\bibitem{distributedImageProcessing} Giloi, W. \textit{Distributed Image Processing}. Advances in Digital Image Processing, pages 249-263. 1979.

\bibitem{mapReduce} Dean, Jeffrey, and Sanjay Ghemawat. \textit{MapReduce: simplified data processing on large clusters.} Communications of the ACM 51.1 (2008): 107-113.

\bibitem{spatialHadoop} Eldawy, A. and Mokbel, M. F. \textit{SpatialHadoop: An Efficient Mapreduce Framework for Spatial Data}. Data Engineering (ICDE), 2015 IEEE 31st International Conference
					
\bibitem{hadoopGIS} Ablimit Aji , Fusheng Wang , Hoang Vo , Rubao Lee , Qiaoling Liu , Xiaodong Zhang , Joel Saltz. 
\textit{Hadoop GIS: a high performance spatial data warehousing system over mapreduce}, Proceedings of the VLDB Endowment, v.6 n.11, p.1009-1020, August 2013

\bibitem{actorOrig} Carl Hewitt, et al. \textit{Actor Induction and Meta-evaluation} Conference Record of ACM Symposium on Principles of Programming Languages, January 1974.

\bibitem{actorErlang} Vinoski, Steve. \textit{Concurrency with Erlang}. IEEE Internet Computing (2007), 11: 90-93

\bibitem{erlang} Armstrong, J. \textit{Erlang}. CACM, 53, 9 (Sept. 2010), 68-75

\bibitem{actorScala} Philipp Haller, Martin Odersky. \textit{Scala Actors: Unifying thread-based and event-based programming}, Theoretical Computer Science, v.410 n.2-3, p.202-220, February, 2009

\bibitem{actorAkka} GUPTA, Munish. \textit{Akka essentials}. Packt Publishing Ltd, 2012.

\bibitem{sfa} Herring, J. \textit{OpenGIS Implementation Standard for Geographic information-Simple feature access-Part 1: Common architecture.} OGC Document 4.21 (2011): 122-127.

\bibitem{gaussianBlur} Nixon, Mark. \textit{Feature Extraction and Image Processing.} Academic Press, 2008.

\bibitem{gaborFilter} Gabor, Dennis. \textit{Theory of communication. Part 1: The analysis of information.} Electrical Engineers-Part III: Radio and Communication Engineering, Journal of the Institution of 93.26 (1946): 429-441.

\bibitem{gaborFilter2} FOGEL, Itzhak; SAGI, Dov. \textit{Gabor filters as texture discriminator}. Biological cybernetics, 1989, 61.2: 103-113.

\bibitem{gaborFilterApplications} T. P. Weldon, W. E. Higgins, and D. F. Dunn. \textit{Gabor filter design for multiple texture segmentation} Optical Engineering, vol. 35, no. 10, pp. 2852-2863, Oct. 1996.

\bibitem{gaborFilterVisualisation} Prasad, V. Shiv Naga, and Justin Domke. \textit{Gabor filter visualization.} J. Atmos. Sci 13 (2005).

\bibitem{quadTree} Samet, Hanan. \textit{The quadtree and related hierarchical data structures.} ACM Computing Surveys (CSUR) 16.2 (1984): 187-260.

\bibitem{sequentialCoupling} Kettig, R. L., Landgrebe, D.A. \textit{Classification of multispectral image data by extraction and classification of homogeneous objects}, Geoscience Electronics, IEEE Transactions on 14.1, pp. 19-26, 1976.

\bibitem{sequentialCoupling2} László, I., Dezsõ, B., Fekete, I., Pröhle, T. \textit{A fully segment-based method for the classification of satellite images}, Annales Univ. Sci. Budapest, Sectio Computatorica. Vol. 30. No. 2009, 2009.

\bibitem{bestMerge} Schoenmakers, Ronald Peter Helena Maria. \textit{Integrated methodology for segmentation of large optical satellite images in land applications of remote sensing}. Office for Official Publications of the European Communities, 1995.

\bibitem{bestMerge2} Fekete I., Dezsõ B, László I., Ócsai K. \textit{A szegmentálás szerepe az ûrfelvételek tematikus osztályozásában}. Informatika a felsõoktatásban 2008 konferencia Debrecen, 2008. augusztus 27-29.

\bibitem{toarefCompute} \textit{Converting Digital Numbers to Top of Atmosphere (ToA) Reflectance} http://www.yale.edu/ceo/Documentation/Landsat\_DN\_to\_Reflectance.pdf

\bibitem{bhattacharyya} Bhattacharyya, Anil. \textit{On a measure of divergence between two multinomial populations} Sankhya: The Indian Journal of Statistics (1946): 401-406.

\bibitem{balancedHistogramThresholding} A. Anjos and H. Shahbazkia. \textit{Bi-Level Image Thresholding - A Fast Method}. BIOSIGNALS 2008. Vol:2. P:70-76.

\bibitem{bhtOptimal} A. Anjos, R. Leite, M. L. Cancela, H. Shahbazkia. \textit{MAQ - A Bioinformatics Tool for Automatic Macroarray Analysis}. International Journal of Computer Applications. 2010. Number 7 - Article 1.

\bibitem{otsu}  Nobuyuki Otsu (1979). \textit{A threshold selection method from gray-level histograms}. IEEE Trans. Sys., Man., Cyber. 9 (1): 62-66

\bibitem{isodata} Ball, Geoffrey H., and David J. Hall. \textit{ISODATA, a novel method of data analysis and pattern classification}. STANFORD RESEARCH INST MENLO PARK CA, 1965.

\end{thebibliography}

\addcontentsline{toc}{chapter}{Ábrajegyzék}
\listoffigures

\end{document}
